{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Regex JSON from the Alphabet and Punctuation JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unicodedata import normalize\n",
    "from pathlib import Path\n",
    "import json\n",
    "import collections\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "nena_dir = Path.home().joinpath('github/CambridgeSemiticsLab/nena_corpus')\n",
    "standards = nena_dir.joinpath('standards')\n",
    "alpha_file = standards.joinpath('alphabet/alphabet.json')\n",
    "punct_file = standards.joinpath('punctuation/punctuation.json')\n",
    "alpha_data = json.loads(alpha_file.read_text())\n",
    "punct_data = json.loads(punct_file.read_text())\n",
    "regex_file = standards.joinpath('NFD_regexes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_patts = []\n",
    "for letter in alpha_data:\n",
    "    lower, upper = letter['decomposed_string'], letter['decomposed_upper_string']\n",
    "    if upper == lower:\n",
    "        upper = ''\n",
    "    combo = '|'.join(c for c in [lower, upper] if c)\n",
    "    alpha_patts.append(combo)\n",
    "    \n",
    "punct_patts = []\n",
    "for punct in punct_data:\n",
    "    punct_patts.append(re.escape(punct[\"decomposed_string\"]))\n",
    "                             \n",
    "alpha_join = '|'.join(alpha_patts)\n",
    "alpha_re = f'({alpha_join})(?![\\u0300-\\u036F])'\n",
    "        \n",
    "re_dict = {\n",
    "    'alphabet': alpha_re,\n",
    "    'punctuation': '|'.join(punct_patts),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['⁺',\n",
       " '\"',\n",
       " '\\\\ ',\n",
       " '\\\\-',\n",
       " '=',\n",
       " 'ˈ',\n",
       " ',',\n",
       " '\\\\.\\\\.\\\\.',\n",
       " ':',\n",
       " '—',\n",
       " ';',\n",
       " '\\\\.',\n",
       " '\\\\?',\n",
       " '!',\n",
       " '\"']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_patts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function escape in module re:\n",
      "\n",
      "escape(pattern)\n",
      "    Escape special characters in a string.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(re.escape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(b|B|c|C|č|Č|c̭|C̭|č̣|Č̣|č̭|Č̭|d|D|ḍ|Ḍ|f|F|g|G|ġ|Ġ|h|H|ḥ|Ḥ|j|J|k|K|k̭|K̭|l|L|ḷ|Ḷ|m|M|ṃ|Ṃ|n|N|p|P|p̣|P̣|p̭|P̭|q|Q|r|R|ṛ|Ṛ|s|S|š|Š|ṣ|Ṣ|t|T|ṭ|Ṭ|ṱ|Ṱ|v|V|w|W|x|X|y|Y|z|Z|ž|Ž|ẓ|Ẓ|ð|Ð|ð̣|Ð̣|ɟ|ʾ|ʿ|θ|Θ|a|A|à|À|á|Á|ā|Ā|ă|Ă|ā̀|Ā̀|ā́|Ā́|ằ|Ằ|ắ|Ắ|e|E|è|È|é|É|ē|Ē|ḕ|Ḕ|ḗ|Ḗ|i|I|ì|Ì|í|Í|ī|Ī|ī̀|Ī̀|ī́|Ī́|o|O|ò|Ò|ó|Ó|ō|Ō|ṑ|Ṑ|ṓ|Ṓ|u|U|ù|Ù|ú|Ú|ū|Ū|ŭ|Ŭ|ū̀|Ū̀|ū́|Ū́|ŭ̀|Ŭ̀|ŭ́|Ŭ́|ə|Ə|ə̀|Ə̀|ə́|Ə́|ɛ|Ɛ|ɛ̀|Ɛ̀|ɛ́|Ɛ́|ɛ̄|Ɛ̄)(?![̀-ͯ])'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_dict['alphabet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⁺|\"|\\\\ |\\\\-|=|ˈ|,|\\\\.\\\\.\\\\.|:|—|;|\\\\.|\\\\?|!|\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_dict['punctuation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = normalize('NFD', nena_dir.joinpath('texts/alpha/Barwar/A Hundred Gold Coins.nena').read_text())\n",
    "test_text = test_file[146:]\n",
    "test_alpha = re.compile(re_dict['alphabet'])\n",
    "test_punct = re.compile(re_dict['punctuation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n(1) xá-ga xèta,ˈ mállah Naṣràdin,ˈ xázəx mòdi wíða.ˈ gu-bɛ̀θa wéwa,ˈ har-zála-w\\nθàya.ˈ z'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l', 'i', 'b', 'q', 'z', 'í', 'w', 'k̭', 'ɛ̀', 'ū̀', 'ṱ', 'ù', 'š', 'u', 'N', 'ṭ', 'ì', 'é', 'ð', 'y', 'o', 'j', 't', 'è', 'ú', 'ằ', 'ò', 'ṣ', 'ă', 'k', 'g', 'p', 'ʿ', 'ə', 'ắ', 'n', 'à', 'ʾ', 'h', 'č̣', 'ē', 'a', 'ɛ', 'x', 'ž', 'á', 'm', 'ó', 'f', 'ɛ́', 'd', 's', 'č', 'r', 'θ', 'e', 'ə́', 'ə̀'}\n"
     ]
    }
   ],
   "source": [
    "found_alphas = set(test_alpha.findall(test_text))\n",
    "found_puncts = set(test_punct.findall(test_text))\n",
    "                   \n",
    "print(found_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ', '!', ',', '-', '.', '?', 'ˈ'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_puncts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(regex_file, 'w') as outfile:\n",
    "    json.dump(re_dict, outfile, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
