{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NenaParser: A parser for Nena Standard Text format\n",
    "\n",
    "The goal of this parser (under development) is to translate texts in the\n",
    "[Nena Standard Text format][nenamd] (we should find a better name for that)\n",
    "into structured groups of morphemes. Those structured morphemes can then be\n",
    "easily converted to (e.g.) TextFabric format.\n",
    "\n",
    "For the Nena Standard Text parser, we make use of [Sly][sly], a Python\n",
    "implementation of the lex/yacc type of parser generators. (This may soon have\n",
    "to be converted to Sly's predecessor [Ply][ply], as Sly works only with\n",
    "Python 3.6+ and the NENA website runs on Python 3.5 - but that should not be\n",
    "difficult).\n",
    "\n",
    "[nenamd]: https://github.com/CambridgeSemiticsLab/nena_corpus/blob/tomarkdown/docs/text_markup.md\n",
    "[sly]: https://sly.readthedocs.io/en/latest/\n",
    "[ply]: http://www.dabeaz.com/ply/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexer\n",
    "\n",
    "The parser needs as its input 'tokens', which are predefined units of characters. These are provided by the 'lexer'. In Sly (and Ply), tokens are defined as regular expressions, of which the matching string is returned as the token value. If the token is defined as a function (with its regular expression as argument to the `@_` decorator), then the returned value (among other things) can be manipulated. For more detailed information, [see the documentation][slydocs].\n",
    "\n",
    "[slydocs]: https://sly.readthedocs.io/en/latest/sly.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SPACE', '\\n'),\n",
       " ('TITLE', ('title', 'Gozáli and Nozali')),\n",
       " ('NEWLINES', '\\n\\n'),\n",
       " ('ATTRIBUTE', ('text_id', 'A8')),\n",
       " ('SPACE', '\\n'),\n",
       " ('ATTRIBUTE', ('informant', 'Nanəs Bənyamən')),\n",
       " ('SPACE', '\\n'),\n",
       " ('ATTRIBUTE', ('place', 'ʾƐn-Nune')),\n",
       " ('NEWLINES', '\\n\\n'),\n",
       " ('(', '('),\n",
       " ('DIGITS', '1'),\n",
       " (')', ')'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTER', 'a'),\n",
       " ('HYPHEN', '-'),\n",
       " ('LETTER', '⁺t'),\n",
       " ('LETTER', 'e'),\n",
       " ('LETTER', 's'),\n",
       " ('LETTER', 't'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTER', 'w'),\n",
       " ('LETTER', 'o'),\n",
       " ('LETTER', 'r'),\n",
       " ('LETTER', 'd'),\n",
       " ('PUNCTUATION', '.'),\n",
       " ('PUNCTUATION', '.'),\n",
       " ('PUNCTUATION', '.'),\n",
       " ('[', '['),\n",
       " ('^', '^'),\n",
       " ('DIGITS', '1'),\n",
       " (']', ']'),\n",
       " ('SPACE', ' '),\n",
       " ('COMMENT', '(a-comment)'),\n",
       " ('SPACE', ' '),\n",
       " ('LBRACKET_COMMENT', '[GK:'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTER', 'l'),\n",
       " ('LETTER', 'a'),\n",
       " ('LETTER', 'l'),\n",
       " ('LETTER', 'a'),\n",
       " ('LETTER', 'l'),\n",
       " ('LETTER', 'a'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTER', 'f'),\n",
       " ('LETTER', 'd'),\n",
       " (']', ']'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTER', 'b'),\n",
       " ('LETTER', 'l'),\n",
       " ('LETTER', 'a'),\n",
       " ('SPACE', ' '),\n",
       " ('/', '/'),\n",
       " ('/', '/'),\n",
       " ('SPACE', '\\n'),\n",
       " ('PUNCTUATION', '‘'),\n",
       " ('LETTER', 'b'),\n",
       " ('LETTER', 'l'),\n",
       " ('LETTER', 'a'),\n",
       " ('LETTER', 't'),\n",
       " ('LETTER', 'w'),\n",
       " ('LETTER', 'o'),\n",
       " ('PUNCTUATION', '’'),\n",
       " ('NEWLINES', '\\n\\n\\n'),\n",
       " ('(', '('),\n",
       " ('DIGITS', '2'),\n",
       " (')', ')'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTER', 'a'),\n",
       " ('LETTER', 'l'),\n",
       " ('LETTER', 's'),\n",
       " ('LETTER', 'o'),\n",
       " ('[', '['),\n",
       " ('^', '^'),\n",
       " ('DIGITS', '2'),\n",
       " (']', ']'),\n",
       " ('SPACE', ' '),\n",
       " ('LANG_MARKER', '<E>'),\n",
       " ('*', '*'),\n",
       " ('LETTER', 'w'),\n",
       " ('LETTER', 'ó'),\n",
       " ('LETTER', 'r'),\n",
       " ('LETTER', 'd'),\n",
       " ('LETTER', 's'),\n",
       " ('*', '*'),\n",
       " ('LANG_MARKER', '<E>'),\n",
       " ('PUNCTUATION', '.'),\n",
       " ('LETTER', 'i'),\n",
       " ('PUNCTUATION', '.'),\n",
       " ('PUNCTUATION', 'ˈ'),\n",
       " ('SPACE', ' '),\n",
       " ('LBRACKET_COMMENT', '[GK:'),\n",
       " ('SPACE', '\\n'),\n",
       " ('LETTER', 'b'),\n",
       " ('HYPHEN', '-'),\n",
       " ('LETTER', 'm'),\n",
       " ('LETTER', 'ú'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTER', 'b'),\n",
       " ('LETTER', 'ə'),\n",
       " ('LETTER', 'c'),\n",
       " ('LETTER', 'n'),\n",
       " ('LETTER', 'à'),\n",
       " ('LETTER', 'š'),\n",
       " ('LETTER', 'ə'),\n",
       " ('LETTER', 'v'),\n",
       " ('LETTER', 'a'),\n",
       " ('PUNCTUATION', '?'),\n",
       " (']', ']'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTER', 'b'),\n",
       " ('HYPHEN', '-'),\n",
       " ('LETTER', 'm'),\n",
       " ('LETTER', 'ù'),\n",
       " ('SPACE', '\\n'),\n",
       " ('(', '('),\n",
       " ('DIGITS', '3'),\n",
       " (')', ')'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTER', 'm'),\n",
       " ('LETTER', 'o'),\n",
       " ('LETTER', 'r'),\n",
       " ('LETTER', 'e'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTER', 'w'),\n",
       " ('LETTER', 'o'),\n",
       " ('LETTER', 'r'),\n",
       " ('LETTER', 'd'),\n",
       " ('LETTER', 's'),\n",
       " ('LETTER', 'č'),\n",
       " ('LETTER', 'x'),\n",
       " ('SPACE', ' '),\n",
       " ('/', '/'),\n",
       " ('SPACE', '\\n'),\n",
       " ('LETTER', 'n'),\n",
       " ('LETTER', 'e'),\n",
       " ('LETTER', 'w'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTER', 'p'),\n",
       " ('LETTER', 'a'),\n",
       " ('LETTER', 'r'),\n",
       " ('LETTER', 'a'),\n",
       " ('LETTER', 'g'),\n",
       " ('LETTER', 'r'),\n",
       " ('LETTER', 'a'),\n",
       " ('LETTER', 'p'),\n",
       " ('LETTER', 'h'),\n",
       " ('SPACE', ' '),\n",
       " ('(', '('),\n",
       " ('DIGITS', '4'),\n",
       " (')', ')'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTER', 'n'),\n",
       " ('LETTER', 'e'),\n",
       " ('LETTER', 'w'),\n",
       " ('HYPHEN', '-'),\n",
       " ('LETTER', 'p'),\n",
       " ('LETTER', 'a'),\n",
       " ('LETTER', 'r'),\n",
       " ('LETTER', 'a'),\n",
       " ('LETTER', 'g'),\n",
       " ('LETTER', 'r'),\n",
       " ('LETTER', 'a'),\n",
       " ('LETTER', 'p'),\n",
       " ('LETTER', 'h'),\n",
       " ('SPACE', ' '),\n",
       " ('PUNCTUATION', '—'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTER', 'p'),\n",
       " ('LETTER', 'a'),\n",
       " ('LETTER', 'u'),\n",
       " ('LETTER', 's'),\n",
       " ('LETTER', 'e'),\n",
       " ('PUNCTUATION', '.'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTER', 't'),\n",
       " ('HYPHEN', '-'),\n",
       " ('LETTER', 'w'),\n",
       " ('LETTER', 'é'),\n",
       " ('LETTER', 'w'),\n",
       " ('LETTER', 'a'),\n",
       " ('SPACE', ' '),\n",
       " ('PUNCTUATION', '.'),\n",
       " ('PUNCTUATION', '.'),\n",
       " ('PUNCTUATION', '.'),\n",
       " ('SPACE', ' '),\n",
       " ('LETTER', 'ʾ'),\n",
       " ('LETTER', 'á'),\n",
       " ('LETTER', 'y'),\n",
       " ('LETTER', 'y'),\n",
       " ('LETTER', 'a'),\n",
       " ('SPACE', '  '),\n",
       " ('LANG_MARKER', '<R>'),\n",
       " ('*', '*'),\n",
       " ('LETTER', 't'),\n",
       " ('LETTER', 's'),\n",
       " ('LETTER', 'é'),\n",
       " ('LETTER', 'n'),\n",
       " ('LETTER', 't'),\n",
       " ('LETTER', 'r'),\n",
       " ('*', '*'),\n",
       " ('LANG_MARKER', '<R>'),\n",
       " ('HYPHEN', '-'),\n",
       " ('LETTER', 'ə'),\n",
       " ('LETTER', 't'),\n",
       " ('NEWLINES', '\\n\\n'),\n",
       " ('FOOTNOTE', (1, 'The ')),\n",
       " ('SPACE', '\\n'),\n",
       " ('FOOTNOTE', (2, 'Second footnote.\\ncontinued.')),\n",
       " ('SPACE', '\\n'),\n",
       " ('FOOTNOTE', (3, 'Third footnote, not referenced in text.\\n'))]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sly import Lexer\n",
    "\n",
    "punct = '.,?!:;–\\u02c8\\u2014\\u2019\\u2018'\n",
    "\n",
    "class NenaLexer(Lexer):\n",
    "    \n",
    "    # set of token names\n",
    "    tokens = {\n",
    "        TITLE, ATTRIBUTE, LETTER, NEWLINES, \n",
    "        NEWLINE,\n",
    "        SPACE, PUNCTUATION, HYPHEN,\n",
    "        LPAREN_COMMENT, LBRACKET_COMMENT, DIGITS,\n",
    "        LANG_MARKER, COMMENT, FOOTNOTE\n",
    "    }\n",
    "    \n",
    "    # NB \\u207A == superscript +\n",
    "    literals = {'*', '(', ')', '{', '}', '[', ']', '/', '^'}\n",
    "\n",
    "    # The '(?m)' part turns on multiline matching, which makes\n",
    "    # it possible to use ^ and $ for the start/end of the line.\n",
    "    # Title starts with pound sign. Returns 2-tuple (key, value).\n",
    "    @_(r'(?m)^\\# .*$')\n",
    "    def TITLE(self, t):\n",
    "        t.value = ('title', t.value[2:])\n",
    "        return t\n",
    "\n",
    "    # Attribute starts key and colon. Returns 2-tuple (key, value).\n",
    "    @_(r'(?m)^[a-z][a-z0-9_]+: .*$')\n",
    "    def ATTRIBUTE(self, t):\n",
    "        t.value = tuple(t.value.split(': '))\n",
    "        return t\n",
    "    \n",
    "    # Footnote starts with '[^n]: ', where n is a number.\n",
    "    # Returns a 2-tuple (int: fn_sym, str: footnote_text)\n",
    "    @_(r'(?m)^\\[\\^[1-9][0-9]*\\]: \\D*$')\n",
    "    def FOOTNOTE(self, t):\n",
    "        fn_sym, footnote = t.value.split(maxsplit=1)\n",
    "        t.value = (int(fn_sym[2:-2]), footnote)\n",
    "        return t\n",
    "\n",
    "    # Punctuation is any normal punctuation symbol and vertical bar.\n",
    "    # as well as a long hyphen (—)\n",
    "    \n",
    "    PUNCTUATION = f'[{punct}]'\n",
    "    \n",
    "    # How to get combined Unicode characters to be recognized?\n",
    "    # Matching only Unicode points of letters with pre-combined\n",
    "    # marks can be done with the 'word' class '\\w', but it\n",
    "    # includes digits and underscore. To remove those, negate\n",
    "    # the inverted word class along with digits and underscore:\n",
    "    # '[^\\W\\d_]. But that does not include separate combining\n",
    "    # marks, or the '+' sign.\n",
    "    # One solution would be unicodedata.normalize('NFC', data),\n",
    "    # except that not all combinations have pre-combined Unicode\n",
    "    # points.\n",
    "    # Another solution is to use an external regex engine such as\n",
    "    # `regex` (`pip install regex`), which has better Unicode\n",
    "    # support. However, I would like to avoid extra dependencies.\n",
    "    # Another (less elegant) solution is to make the '+' symbol\n",
    "    # and the combining characters [\\u0300-\\u036F] each its own\n",
    "    # token, which the parser will have to parse into morphemes\n",
    "    # and words.\n",
    "    # Another (also less elegant) solution is to use a 'negative\n",
    "    # lookbehind assertion' for the negation of digits and '_':\n",
    "    # https://stackoverflow.com/a/12349464/9230612\n",
    "    # (?!\\d_)[\\w\\u0300-\\u036F]+\n",
    "    # Because combining marks can never appear before the first\n",
    "    # letter, and because some dialects have a '+' sign at the\n",
    "    # beginning of some words, we prefix an optional '+' symbol\n",
    "    # and an obligatory '[^\\W\\d_]' before the negative lookbehind.\n",
    "    \n",
    "    # One letter with (or without) combining marks can be matched\n",
    "    # with: [^\\W\\d_][\\u0300-\\u036F]*\n",
    "    # We also add a superscript plus (U-207A) as part of a letter, \n",
    "    # since this char is not a letter on its own, but rather\n",
    "    # modifies the quality of a consonant\n",
    "    # PUNCTUATION is also excluded\n",
    "    LETTER = f'[\\u207A]?[^\\W\\d_{punct}][\\u0300-\\u036F]*'\n",
    "    \n",
    "    # we try to make a LETTERS token:\n",
    "#     LETTERS = r'[+]?[^\\W\\d_](?!\\d_)[\\w\\u0300-\\u036F+]*'\n",
    "    # Unfortunately, with python's `re` it seems impossible to repeat\n",
    "    # a group like this. So we will group the letters in the parser.\n",
    "    \n",
    "    # Newlines: boundaries of paragraphs and metadata are marked\n",
    "    # with two newlines (meaning an empty line). The empty line\n",
    "    # may contain whitespace.\n",
    "    NEWLINES = r'\\n\\s*\\n\\s*'\n",
    "        \n",
    "    # Space is any successive number of whitespace symbols.\n",
    "    SPACE = r'\\s+'\n",
    "    # One or more digits, not starting with zero\n",
    "    DIGITS = r'[1-9][0-9]*'\n",
    "    # Line id is any number of digits surrounded by round brackets\n",
    "#     LINE_ID = r'\\([0-9]+\\)'  # TODO convert to int?\n",
    "    # There are two different hyphens, a single one and a double one.\n",
    "    # The double one is the 'equals' sign.\n",
    "    HYPHEN = r'[-=]'\n",
    "    # Language markers are ASCII letter strings surrounded by\n",
    "    # angle brackets.\n",
    "    LANG_MARKER = r'<[A-Za-z]+>'\n",
    "    # A special comment starts with an opening bracket, capital initials\n",
    "    # and a colon.\n",
    "    LPAREN_COMMENT = r'\\([A-Za-z]+:'\n",
    "    LBRACKET_COMMENT = r'\\[[A-Za-z]+:'\n",
    "    # A regular comment is text (at least one character not being a digit)\n",
    "    # which may not contain a colon (otherwise it becomes a special comment/interruption)\n",
    "    COMMENT = r'\\([^:)]*[^:)\\d]+[^:)]*\\)'\n",
    "\n",
    "lexer_test = \"\"\"\n",
    "# Gozáli and Nozali\n",
    "\n",
    "text_id: A8\n",
    "informant: Nanəs Bənyamən\n",
    "place: ʾƐn-Nune\n",
    "\n",
    "(1) a-\\u207Atest word...[^1] (a-comment) [GK: lalala fd] bla //\n",
    "\\u2018blatwo\\u2019\n",
    "\n",
    "\n",
    "(2) also[^2] <E>*wórds*<E>.i.ˈ [GK:\n",
    "b-mú bəcnàšəva?] b-mù\n",
    "(3) more wordsčx /\n",
    "new paragraph (4) new-paragraph — pause. t-wéwa ... ʾáyya  <R>*tséntr*<R>-ət\n",
    "\n",
    "[^1]: The \n",
    "[^2]: Second footnote.\n",
    "continued.\n",
    "[^3]: Third footnote, not referenced in text.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# demonstration of output results of lexer, to be used by parser below\n",
    "lexer = NenaLexer()\n",
    "[(tok.type, tok.value) for tok in lexer.tokenize(lexer_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_coins = \"\"\"\\\n",
    "# A Hundred Gold Coins\n",
    "\n",
    "source: bar text a1-A7.html\n",
    "text_id: A6\n",
    "informant: Yuwəl Yuḥanna\n",
    "place: Dure\n",
    "\n",
    "(1) xá-ga xèta,ˈ mállah Naṣràdin,ˈ xázəx mòdi wíða.ˈ gu-bɛ̀θa wéwa,ˈ har-zála-w\n",
    "θàya.ˈ zála-w θàya,ˈ mára ya-ʾàlaha,ˈ yawə̀tliˈ ʾə́mma dàwe.ˈ ʾən-hàwaˈ ʾə́č̣č̣i-u\n",
    "ʾə́č̣č̣a maqəlbə̀nna.ˈ ʾu-ʾən-hàwaˈ ʾə́mma-w-xà-ži,ˈ la-băyə̀nna.ˈ de-šùqla.ˈ ʾə̀mma\n",
    "gắrəg háwa drə́st.ˈ (2) b-álaha hóle zála-w θàya,ˈ ʾíθwale xá-šwawa huðàya,ˈ\n",
    "maṣóθe ʾə́lle dìye.ˈ mə́re xázəx ʾáwwa dū̀s-ile.ˈ qɛ́mən mjarbə̀nne.ˈ síqa l-gàre,ˈ\n",
    "də́ryɛle ʾə́č̣č̣i-u ʾə́č̣č̣a dáwe gu-ða-kìsta,ˈ də́rya b-kàwele.ˈ ʾá báxta hàyyo!ˈ hóle\n",
    "ʾaláha qəm-mšadə̀rrən.ˈ (3) muθɛ́θɛla màjma.ˈ msúrqəlla píšela mnáyəlla l-xà-xa.ˈ\n",
    "plíṭla ʾə́č̣č̣i-u ʾə̀č̣č̣a.ˈ trè,ˈ trè,ˈ ʾə́č̣č̣i-u ʾə̀č̣č̣a.ˈ ʾə̀ṣra,ˈ ʾə̀ṣra,ˈ hàr-ʾəč̣č̣i-u\n",
    "ʾə́č̣č̣a.ˈ klèla,ˈ ʾámər báxta dū̀s-ile.ˈ ʾaláha là-xaləṭ.ˈ ʾə́č̣č̣i-u ʾə̀č̣č̣a,ˈ ʾáxči\n",
    "ʾána max-xšàwti,ˈ ʾáyya kìstaˈ hóle mxožə́bnəlla max-xà.ˈ ha-šqùl,ˈ máttula\n",
    "tămàha.ˈ (4) huðáya l-gàreˈ šwirɛ́le l-pàlga,ˈ yába ʾànən mšúdrəlla!ˈ ʾáy kálba\n",
    "ʾámər táma l-gàre maṣyóθe,ˈ bắyət šaqlə́tla ʾap-ʾànna.ˈ mrázgət gànux.ˈ tə́mməl\n",
    "ṱ-ásqəx kəs-qàzi.ˈ huðáya ʾə́č̣č̣i-u ʾə́č̣č̣a dáwe zìle mə́nne,ˈ ʾɛ́ka ṱ-áθya šə̀nθe?!ˈ\n",
    "hal-qedámta šə́nθe la-θèla.ˈ hár-wele zála-w θàya.ˈ (5) málla múttəlle réše\n",
    "dmìxa.ˈ ṭlìya,ˈ kéfe basìmta,ˈ ʾu-dáwe xo-rèše.ˈ sáʾət ʾə́šta mbàdlaˈ ʾə́θyɛle\n",
    "huðáya wáða ṭəq-ṭəq-ṭə́q l-ṭằra.ˈ ʾu-qáre l-tằraˈ mòdila qə́ṣṣət?ˈ (6) pθíxəlle\n",
    "tắra màlla,ˈ ʾína huðáya lwíša kášxa-w júlle xàθe.ˈ ʾu-xmárte díye msúrgəlla-w\n",
    "wíðəlla tàza.ˈ ṭla-mòdila ʾáyya?ˈ mə́re ṱ-ásqəx kəs-qàzi.ˈ mə́re sì kálba.ˈ ʾána\n",
    "là-ʾaθən mə́nnux.ˈ ṭla-mò la-ʾáθət mə́nni?ˈ sí là-ʾaθən mə́nnux ʾána.ˈ (7) ṭla-mò?ˈ\n",
    "mòdila qə́ṣṣət?ˈ mə́re ʾaláha-w náše yằði.ˈ xazɛ́la ʾánna júllux hàtxa,ˈ kášxa-w\n",
    "ʾáyya xmàrtuxˈ ʾu-sɛ̀rga-wˈ w-ána b-ánna dašdàše-wˈ b-ánna čak̭àlle-wˈ\n",
    "ʾu-šəxtàna-wˈ šárṭ qázi t-yawə́lla ṭlàlux.ˈ (8) qázi ṱ-awə́dla ṭlàlux,ˈ lá-ʾawədla\n",
    "ṭlàli.ˈ mə́re là-ʾaθən,ˈ ʾína júllux hálla ṭlàli.ˈ ʾu-xmártux ṱ-átwən ʾàna\n",
    "l-xáṣa.ˈ ʾu-ʾáti luš-jùlliˈ ʾu-ṱ-àsqəx.ˈ hám-ʾən ʾàsqətˈ ʾap-ʾáyya qabū̀l-ila.ˈ\n",
    "(9) qímɛle ʾaw-lwíša dašdàšət málla,ˈ ʾu-čak̭àllət málla,ˈ málla lwíšɛle kášxa\n",
    "d-o-huðàyaˈ ʾu-tíwɛle xáṣət xmàrta,ˈ ʾu-síqela kəs-qàzi.ˈ síqɛle kəs-qàzi,ˈ\n",
    "wírela šarṭ-qàzi.ˈ mòdila qə́ṣṣət?ˈ (10) málla mə̀reˈ qázi ṱ-áwət basìma.ˈ ʾána\n",
    "kəmà dána ṱ-in-mṣalóye ṭla-márya ʾàlahaˈ ta-t-yawə́lli ʾə̀mma dáwe.ˈ ʾu-ʾáwwa\n",
    "huðáya wéle maṣyóθe nṭára ʾə́lli l-gàre.ˈ ʾu-ʾálaha šuxa-l-šə́mme qəm-mšadə́rri\n",
    "ʾə́č̣č̣i-u ʾə́č̣č̣a dàwe.ˈ ʾu-ʾána mə́ri bàxta,ˈ ʾáp ʾayya-kìstaˈ ʾálaha mxožə́bnəlla\n",
    "m-gēb-xà-dawa.ˈ (11) ʾu-ʾáwwa-ži huðáya l-gàreˈ ʾə̀lla,ˈ ʾánna dáwe ʾànən\n",
    "hiwə́llux.ˈ ʾu-hátxa be-bằxət-ile,ˈ yá-qazi ṱ-áwət basìma,ˈ ʾáwwa huðàya,ˈ yáʿni\n",
    "díya gu-pàθuxˈ mdàgəlˈ ʾu-sàru.ˈ mə́re xzí hátxa be-nxə̀pθɛle.ˈ lá ʾítle nxə̀pθa.ˈ\n",
    "(12) díya ṱ-àmərˈ ʾáp ʾanna-júlle ṱ-ilà-lluxˈ ʾu-ʾáyya xmárta dìyila.ˈ w-áti\n",
    "xə́zyətli ʾána tíwa l-xàṣa.ˈ huðáya mə̀reˈ dìyila!ˈ ʾína d-ɛ̀nila?ˈ qázi mə́re qùˈ\n",
    "kálba brət-kálba huðàya.ˈ ʾámər sí šarṭ-dìyuxile.ˈ\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing a `.nena` file\n",
    "\n",
    "Below is a representation of the tree-like structure of a NENA standard text file. This is the structure that the parser must recognize and reproduce.\n",
    "\n",
    "```\n",
    "text\n",
    "  |\n",
    "  heading\n",
    "  |  |\n",
    "  |  attributes\n",
    "  |    |\n",
    "  |    attribute (e.g. title, informant, etc.)\n",
    "  | \n",
    "  paragraphs\n",
    "    |\n",
    "    paragraph\n",
    "    |  |\n",
    "    |  lines\n",
    "    |    |\n",
    "    |    line\n",
    "    |      |\n",
    "    |      line elements (in any order)\n",
    "    |        |\n",
    "    |        stress group\n",
    "    |        |  |\n",
    "    |        |  word normal (+metadata, e.g. trailer, etc.)\n",
    "    |        |  |\n",
    "    |        |  word foreign (+metadata)\n",
    "    |        |  |\n",
    "    |        |  word language (+metadata)\n",
    "    |        |    |\n",
    "    |        |    letter\n",
    "    |        |\n",
    "    |        footnote\n",
    "    |        |\n",
    "    |        comment\n",
    "    |        |\n",
    "    |        interruption\n",
    "    |      \n",
    "    orphaned footnote (processed later)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morpheme class\n",
    "\n",
    "To conveniently store the morpheme and its features, we prepare a small `Morpheme` class, to be used by the parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morpheme:\n",
    "    \n",
    "    def __init__(self, value, trailer='',\n",
    "                 footnotes=None, speaker=None,\n",
    "                 foreign=False, lang=None):\n",
    "        self.value = value  # list of (combined) characters\n",
    "        self.trailer = trailer  # str (TODO: make this a list as well?)\n",
    "        self.footnotes = footnotes if footnotes is not None else {}  # dict\n",
    "        self.speaker = speaker  # str\n",
    "        self.foreign = foreign  # boolean\n",
    "        self.lang = lang  # str\n",
    "    \n",
    "    def __str__(self):\n",
    "        return ''.join(self.value)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        sp = f' speaker {self.speaker!r}' if self.speaker else ''\n",
    "        fr = ' foreign' if self.foreign else ''\n",
    "        ln = f' lang {self.lang!r}' if self.lang else ''\n",
    "        fn = f' fn_anc {\",\".join(str(n) for n in self.footnotes)!r}' if self.footnotes else ''\n",
    "        fn = f' fn_anc {self.footnotes!r}' if self.footnotes else ''\n",
    "        return f'<Morpheme {str(self)!r} trailer {self.trailer!r}{sp}{fr}{ln}{fn}>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parser\n",
    "\n",
    "The parser processes the tokens provided by the lexer, and tries to combine them into structured units. Those units are defined in the methods of the `NenaParser` class, with the patterns passed as arguments to the `@_` decorator.\n",
    "\n",
    "The top unit (in this case, `text`) is returned as the result of the parsing, and in this case contains a tuple `(heading, paragraphs)`.\n",
    "\n",
    "The value `heading` contains a dictionary with the text metadata. The value `paragraphs` is a list, in which each element contains a list of `lines`. Each element of `lines` is a 2-tuple containing an `int` line identifier, and a list of `line_elements`. The values of `line_elements` are `Morpheme` objects, or 2-tuples with comments in the form `('comment', str)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Token 'NEWLINE' defined, but not used\n",
      "WARNING: There is 1 unused token\n",
      "WARNING: 17 shift/reduce conflicts\n",
      "Parser debugging for NenaParser written to parser.out\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'title': 'Gozáli and Nozali',\n",
       "  'text_id': 'A8',\n",
       "  'informant': 'Nanəs Bənyamən',\n",
       "  'place': 'ʾƐn-Nune'},\n",
       " [[(1,\n",
       "    [<Morpheme 'a' trailer '-'>,\n",
       "     <Morpheme '⁺test' trailer ' '>,\n",
       "     <Morpheme 'word' trailer '... ' fn_anc {1: 'The '}>,\n",
       "     ('comment', 'a-comment'),\n",
       "     <Morpheme 'lalala' trailer ' ' speaker 'GK'>,\n",
       "     <Morpheme 'fd' trailer ' ' speaker 'GK'>,\n",
       "     <Morpheme 'bla' trailer ' //‘'>,\n",
       "     <Morpheme 'blatwo' trailer '’'>])],\n",
       "  [(2,\n",
       "    [<Morpheme 'also' trailer ' ' fn_anc {2: 'Second footnote.\\ncontinued.'}>,\n",
       "     <Morpheme 'wórds' trailer '.' foreign lang 'E'>,\n",
       "     <Morpheme 'i' trailer '.ˈ '>,\n",
       "     <Morpheme 'b' trailer '-' speaker 'GK'>,\n",
       "     <Morpheme 'mú' trailer ' ' speaker 'GK'>,\n",
       "     <Morpheme 'bəcnàšəva' trailer '? ' speaker 'GK'>,\n",
       "     <Morpheme 'b' trailer '-'>,\n",
       "     <Morpheme 'mù' trailer ' '>]),\n",
       "   (3,\n",
       "    [<Morpheme 'more' trailer ' '>,\n",
       "     <Morpheme 'wordsčx' trailer ' /'>,\n",
       "     <Morpheme 'new' trailer ' '>,\n",
       "     <Morpheme 'paragraph' trailer ' '>]),\n",
       "   (4,\n",
       "    [<Morpheme 'new' trailer '-'>,\n",
       "     <Morpheme 'paragraph' trailer ' — '>,\n",
       "     <Morpheme 'pause' trailer '. '>,\n",
       "     <Morpheme 't' trailer '-'>,\n",
       "     <Morpheme 'wéwa' trailer ' ... '>,\n",
       "     <Morpheme 'ʾáyya' trailer ' '>,\n",
       "     <Morpheme 'tséntr' trailer '-' foreign lang 'R'>,\n",
       "     <Morpheme 'ət' trailer ''>])],\n",
       "  ('footnotes', {3: 'Third footnote, not referenced in text.\\n\\n'})])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sly import Parser\n",
    "\n",
    "# dict stack to contain footnote anchors,\n",
    "# until the corresponding footnote is encountered.\n",
    "fn_anchors = {}\n",
    "\n",
    "class NenaParser(Parser):\n",
    "    \n",
    "    debugfile = 'parser.out'\n",
    "\n",
    "    # Get the token list from the lexer (required)\n",
    "    tokens = NenaLexer.tokens\n",
    "    \n",
    "    def error(self, t):\n",
    "        #print('ERROR:')\n",
    "        #print(f'\\tunexpected string {repr(t.value[0])} at index {t.index}')\n",
    "        raise Exception(f'unexpected string {repr(t.value[0])} at index {t.index}')\n",
    "    \n",
    "    @_('heading NEWLINES paragraphs')\n",
    "    def text(self, p):\n",
    "        return (p.heading, p.paragraphs)\n",
    "    \n",
    "    # -- HEADING --\n",
    "    \n",
    "    @_('SPACE TITLE NEWLINES attributes',\n",
    "       'TITLE NEWLINES attributes')\n",
    "    def heading(self, p):\n",
    "        key, value = p.TITLE\n",
    "        heading = {key: value}\n",
    "        heading.update(p.attributes)\n",
    "        return heading\n",
    "    \n",
    "    @_('attributes space ATTRIBUTE')\n",
    "    def attributes(self, p):\n",
    "        key, value = p.ATTRIBUTE\n",
    "        p.attributes[key] = value\n",
    "        return p.attributes \n",
    "    \n",
    "    @_('ATTRIBUTE')\n",
    "    def attributes(self, p):\n",
    "        key, value = p.ATTRIBUTE\n",
    "        return {key: value}\n",
    "    \n",
    "    # -- PARAGRAPHS --\n",
    "    \n",
    "    @_('paragraphs NEWLINES paragraph')\n",
    "    def paragraphs(self, p):\n",
    "        # handle cases of null footnotes\n",
    "        if p.paragraph is not None:\n",
    "            return p.paragraphs + [p.paragraph]\n",
    "        else:\n",
    "            return p.paragraphs\n",
    "        \n",
    "    @_('paragraph')\n",
    "    def paragraphs(self, p):\n",
    "        return [p.paragraph]\n",
    "    \n",
    "    # paragraph\n",
    "    @_('paragraph line')\n",
    "    def paragraph(self, p):\n",
    "        return p.paragraph + [p.line]\n",
    "    \n",
    "    # paragraph from orphaned footnotes\n",
    "    @_('footnotes')\n",
    "    def paragraph(self, p):\n",
    "        if p.footnotes:\n",
    "            # TODO: issue log warning about\n",
    "            # unreferenced footnotes?\n",
    "            return ('footnotes', p.footnotes)\n",
    "    \n",
    "    # -- FOOTNOTES -- \n",
    "    \n",
    "    @_('footnotes footnote')\n",
    "    def footnotes(self, p):\n",
    "        p.footnotes.update(p.footnote)\n",
    "        return p.footnotes\n",
    "    \n",
    "    @_('footnote')\n",
    "    def footnotes(self, p):\n",
    "        return p.footnote\n",
    "    \n",
    "    @_('FOOTNOTE space NEWLINES',\n",
    "       'FOOTNOTE NEWLINES',\n",
    "       'FOOTNOTE space',\n",
    "       'FOOTNOTE')\n",
    "    def footnote(self, p):\n",
    "        fn_sym, fn_str = p.FOOTNOTE\n",
    "        footnote = {}\n",
    "        try:\n",
    "            # lookup the fn_sym key in the fn_anchors dict,\n",
    "            # and add the footnote to the appropriate morpheme\n",
    "            fn_morpheme = fn_anchors.pop(fn_sym)\n",
    "            fn_morpheme.footnotes[fn_sym] = fn_str\n",
    "        except KeyError:\n",
    "            # This means there is not footnote anchor\n",
    "            # referring to this footnote. So we return\n",
    "            # the footnote to the text\n",
    "            footnote = {fn_sym: fn_str}\n",
    "        return footnote\n",
    "\n",
    "    # -- LINES --\n",
    "    \n",
    "    @_('line')\n",
    "    def paragraph(self, p):\n",
    "        return [p.line]\n",
    "    \n",
    "    @_('line_id line_elements')\n",
    "    def line(self, p):\n",
    "        return (p.line_id, p.line_elements)\n",
    "    \n",
    "    @_('\"(\" DIGITS \")\" SPACE')\n",
    "    def line_id(self, p):\n",
    "        return int(p.DIGITS)\n",
    "\n",
    "    @_('line_elements line_element',\n",
    "       'line_element')\n",
    "    def line_elements(self, p):\n",
    "        if len(p) == 2:\n",
    "            return p.line_elements + p.line_element\n",
    "        else:\n",
    "            return p.line_element\n",
    "    \n",
    "    @_('morphemes',\n",
    "       'fn_anchor',\n",
    "       'interruption',\n",
    "       'morphemes_foreign',\n",
    "       'morphemes_language',\n",
    "       'comment')\n",
    "    def line_element(self, p):\n",
    "        return p[0]\n",
    "    \n",
    "    # -- MORPHEMES -- \n",
    "\n",
    "    # morphemes_language\n",
    "    @_('lang morphemes_foreign morpheme_trailer lang trailer',\n",
    "       'lang morphemes_foreign lang trailer',\n",
    "       'lang morphemes_foreign lang',\n",
    "       'lang morphemes_foreign')\n",
    "    def morphemes_language(self, p):\n",
    "        # check if language markers correspond\n",
    "        if len(p) > 2:\n",
    "            lang = p.lang0\n",
    "            if p.lang0 != p.lang1:\n",
    "                pass  # TODO issue warning: language markers do not correspond\n",
    "        else:\n",
    "            lang = p.lang  # TODO issue warning: missing second language marker\n",
    "        for m in p.morphemes_foreign:\n",
    "            m.lang = lang\n",
    "        if len(p) == 4:\n",
    "            p.morphemes_foreign[-1].trailer += p.trailer\n",
    "        elif len(p) == 5:\n",
    "            p.morpheme_trailer.trailer += p.trailer\n",
    "            p.morphemes_foreign.append(morpheme_trailer)\n",
    "        return p.morphemes_foreign\n",
    "    \n",
    "    # lang\n",
    "    @_('LANG_MARKER')\n",
    "    def lang(self, p):\n",
    "        return p.LANG_MARKER[1:-1]\n",
    "\n",
    "    # morphemes_foreign\n",
    "    # last morpheme may not include trailer\n",
    "    # add trailer after second asterisk to last morpheme\n",
    "    @_('\"*\" morphemes letters \"*\" trailer',\n",
    "       '\"*\" morphemes letters \"*\"',\n",
    "       '\"*\" letters \"*\" trailer',\n",
    "       '\"*\" letters \"*\"',\n",
    "      )\n",
    "    def morphemes_foreign(self, p):\n",
    "        try:\n",
    "            trailer = p.trailer\n",
    "        except KeyError:\n",
    "            trailer = ''\n",
    "        try:\n",
    "            morphemes = p.morphemes\n",
    "        except KeyError:\n",
    "            morphemes = []\n",
    "        morphemes.append(Morpheme(p.letters, trailer=trailer))\n",
    "        for m in morphemes:\n",
    "            m.foreign = True\n",
    "        return morphemes\n",
    "    \n",
    "    # comment\n",
    "    @_('COMMENT trailer',\n",
    "       'COMMENT')\n",
    "    def comment(self, p):\n",
    "        return [('comment', p.COMMENT[1:-1])]\n",
    "\n",
    "    # interruption\n",
    "    @_('LPAREN_COMMENT space morphemes \")\" trailer',\n",
    "       'LPAREN_COMMENT space morphemes \")\"',\n",
    "       'LBRACKET_COMMENT space morphemes \"]\" trailer',\n",
    "       'LBRACKET_COMMENT space morphemes \"]\"')\n",
    "    def interruption(self, p):\n",
    "        speaker = p[0][1:-1]\n",
    "        for m in p.morphemes:\n",
    "            m.speaker = speaker\n",
    "        try:\n",
    "            trailer = p.trailer\n",
    "            if (p.morphemes[-1].trailer.endswith(' ')\n",
    "                and trailer.startswith(' ')):\n",
    "                trailer = trailer[1:]\n",
    "            p.morphemes[-1].trailer += trailer\n",
    "        except KeyError:\n",
    "            pass\n",
    "        return p.morphemes\n",
    "    \n",
    "    # morphemes\n",
    "    @_('morphemes morpheme_trailer',\n",
    "       'morpheme_trailer')\n",
    "    def morphemes(self, p):\n",
    "        if len(p) == 2:\n",
    "            return p.morphemes + [p.morpheme_trailer]\n",
    "        else:\n",
    "            return [p.morpheme_trailer]\n",
    "    \n",
    "    # -- MORPHEME ATTRIBUTES --\n",
    "    \n",
    "    # morpheme_trailer\n",
    "    @_('letters trailer',\n",
    "       'letters')\n",
    "    def morpheme_trailer(self, p):\n",
    "        if len(p) == 2:\n",
    "            trailer = p[1]\n",
    "        else:\n",
    "            trailer = ''\n",
    "        return Morpheme(p.letters, trailer=trailer)\n",
    "\n",
    "    # morpheme_trailer with footnote anchor\n",
    "    @_('morpheme_trailer fn_anchor trailer',\n",
    "       'morpheme_trailer fn_anchor')\n",
    "    def morpheme_trailer(self, p):\n",
    "        if len(p) == 3:\n",
    "            if (p.morpheme_trailer.trailer.endswith(' ')\n",
    "                and p.trailer.startswith(' ')):\n",
    "                p.trailer = p.trailer[1:]\n",
    "            p.morpheme_trailer.trailer += p.trailer\n",
    "        # add dummy value {fn_anc: None} to footnote dict\n",
    "        p.morpheme_trailer.footnotes[p.fn_anchor] = None\n",
    "        # add morpheme object to fn_anchors dict,\n",
    "        # for easy access when footnote text is found\n",
    "        fn_anchors[p.fn_anchor] = p.morpheme_trailer\n",
    "        return p.morpheme_trailer\n",
    "    \n",
    "    # --VARIOUS--\n",
    "    \n",
    "    @_('\"[\" \"^\" DIGITS \"]\"')\n",
    "    def fn_anchor(self, p):\n",
    "        return int(p.DIGITS)\n",
    "        \n",
    "    @_('letters LETTER')\n",
    "    def letters(self, p):\n",
    "        return p.letters + [p.LETTER]\n",
    "    \n",
    "    @_('LETTER')\n",
    "    def letters(self, p):\n",
    "        return [p[0]]\n",
    "    \n",
    "    # trailer\n",
    "    @_('trailer versebreak',\n",
    "       'trailer linebreak',\n",
    "       'trailer PUNCTUATION',\n",
    "       'trailer space',\n",
    "       'PUNCTUATION',\n",
    "       'space',\n",
    "       'HYPHEN',\n",
    "      )\n",
    "    def trailer(self, p):\n",
    "        return ''.join(p)\n",
    "    \n",
    "    # -- LITERALS --\n",
    "    \n",
    "    # reduce any number of spaces (\\s+)\n",
    "    # to a single space (' ')\n",
    "    @_('SPACE')\n",
    "    def space(self, p):\n",
    "        return ' '\n",
    "    \n",
    "    @_('\"/\" \"/\"',\n",
    "       '\"/\" \"/\" space',\n",
    "       '\"/\" \"/\" NEWLINES',\n",
    "       '\"/\" \"/\" space NEWLINES')\n",
    "    def versebreak(self, p):\n",
    "        return '//'\n",
    "    \n",
    "    @_('\"/\"',\n",
    "       '\"/\" space',\n",
    "       '\"/\" NEWLINES',\n",
    "       '\"/\" space NEWLINES')\n",
    "    def linebreak(self, p):\n",
    "        return '/'\n",
    "    \n",
    "parser_test = \"\"\"\n",
    "# Gozáli and Nozali\n",
    "\n",
    "text_id: A8\n",
    "informant: Nanəs Bənyamən\n",
    "place: ʾƐn-Nune\n",
    "\n",
    "(1) a-\\u207Atest word...[^1] (a-comment) [GK: lalala fd] bla //\n",
    "\\u2018blatwo\\u2019\n",
    "\n",
    "\n",
    "(2) also[^2] <E>*wórds*<E>.i.ˈ [GK:\n",
    "b-mú bəcnàšəva?] b-mù\n",
    "(3) more wordsčx /\n",
    "new paragraph (4) new-paragraph — pause. t-wéwa ... ʾáyya  <R>*tséntr*<R>-ət\n",
    "\n",
    "[^1]: The \n",
    "[^2]: Second footnote.\n",
    "continued.\n",
    "[^3]: Third footnote, not referenced in text.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# demonstration of output results of parser, to be used by generate_TF loop\n",
    "parser = NenaParser()\n",
    "parser.parse(lexer.tokenize(parser_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parser output\n",
    "\n",
    "The parser prints a warning that there were shift/reduce conflicts, probably caused by ambiguous whitespace. That is not a problem (although not very elegant, ideally it should be fixed). The parser resolves the conflicts automatically.\n",
    "\n",
    "The output of the example text shows that the parser succeeded to parse it, and structure it into heading, paragraphs, lines and morphemes, with the features stored in the Morpheme object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with Real Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "data_dir = Path('../nena/0.01')\n",
    "dialect_dirs = list(Path(data_dir).glob('*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Parse On All Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Dialect ../nena/0.01/corrections.sh--\n",
      "\n",
      "--Dialect ../nena/0.01/Barwar--\n",
      "\n",
      "trying: A Hundred Gold Coins.nena\n",
      "\t√\n",
      "trying: A Man Called Čuxo.nena\n",
      "\t√\n",
      "trying: A Tale Of A Prince And A Princess.nena\n",
      "\t√\n",
      "trying: A Tale Of Two Kings.nena\n",
      "\t√\n",
      "trying: Baby Leliθa.nena\n",
      "\t√\n",
      "trying: Dəmdəma.nena\n",
      "\t√\n",
      "trying: Gozali And Nozali.nena\n",
      "\t√\n",
      "trying: I Am Worth The Same As A Blind Wolf.nena\n",
      "\t√\n",
      "trying: Man Is Treacherous.nena\n",
      "\t√\n",
      "trying: Measure For Measure.nena\n",
      "\t√\n",
      "trying: Nanno And Jəndo.nena\n",
      "\t√\n",
      "trying: Qaṭina Rescues His Nephew From Leliθa.nena\n",
      "\t√\n",
      "trying: Sour Grapes.nena\n",
      "\t√\n",
      "trying: Tales From The 1001 Nights.nena\n",
      "\t√\n",
      "trying: The Battle With Yuwanəs The Armenian.nena\n",
      "\t√\n",
      "trying: The Bear And The Fox.nena\n",
      "\t√\n",
      "trying: The Brother Of Giants.nena\n",
      "\t√\n",
      "trying: The Cat And The Mice.nena\n",
      "\t√\n",
      "trying: The Cooking Pot.nena\n",
      "\t√\n",
      "trying: The Crafty Hireling.nena\n",
      "\t√\n",
      "trying: The Crow And The Cheese.nena\n",
      "\t√\n",
      "trying: The Daughter Of The King.nena\n",
      "\t√\n",
      "trying: The Fox And The Lion.nena\n",
      "\t√\n",
      "trying: The Fox And The Miller.nena\n",
      "\t√\n",
      "trying: The Fox And The Stork.nena\n",
      "\t√\n",
      "trying: The Giant’s Cave.nena\n",
      "\t√\n",
      "trying: The Girl And The Seven Brothers.nena\n",
      "\t√\n",
      "trying: The King With Forty Sons.nena\n",
      "\t√\n",
      "trying: The Leliθa From Č̭āl.nena\n",
      "\t√\n",
      "trying: The Lion King.nena\n",
      "\t√\n",
      "trying: The Lion With A Swollen Leg.nena\n",
      "\t√\n",
      "trying: The Man Who Cried Wolf.nena\n",
      "\t√\n",
      "trying: The Man Who Wanted To Work.nena\n",
      "\t√\n",
      "trying: The Monk And The Angel.nena\n",
      "\t√\n",
      "trying: The Monk Who Wanted To Know When He Would Die.nena\n",
      "\t√\n",
      "trying: The Priest And The Mullah.nena\n",
      "\t√\n",
      "trying: The Sale Of An Ox.nena\n",
      "\t√\n",
      "trying: The Scorpion And The Snake.nena\n",
      "\t√\n",
      "trying: The Selfish Neighbour.nena\n",
      "\t√\n",
      "trying: The Sisisambər Plant.nena\n",
      "\t√\n",
      "trying: The Story With No End.nena\n",
      "\t√\n",
      "trying: The Tale Of Farxo And Səttiya.nena\n",
      "\t√\n",
      "trying: The Tale Of Mămo And Zine.nena\n",
      "\t√\n",
      "trying: The Tale Of Mərza Pămət.nena\n",
      "\t√\n",
      "trying: The Tale Of Nasimo.nena\n",
      "\t√\n",
      "trying: The Tale Of Parizada, Warda And Nargis.nena\n",
      "\t√\n",
      "trying: The Tale Of Rustam (1).nena\n",
      "\t√\n",
      "trying: The Tale Of Rustam (2).nena\n",
      "\t√\n",
      "trying: The Wise Daughter Of The King.nena\n",
      "\t√\n",
      "trying: The Wise Snake.nena\n",
      "\t√\n",
      "trying: The Wise Young Man.nena\n",
      "\t√\n",
      "trying: Šošət Xere.nena\n",
      "\t√\n",
      "--Dialect ../nena/0.01/reline.py--\n",
      "\n",
      "--Dialect ../nena/0.01/Urmi_C--\n",
      "\n",
      "trying: A Close Shave.nena\n",
      "\t√\n",
      "trying: A Cure For A Husband’s Madness.nena\n",
      "\t√\n",
      "trying: A Donkey Knows Best.nena\n",
      "\t√\n",
      "trying: A Dragon In The Well.nena\n",
      "\t√\n",
      "trying: A Dutiful Son.nena\n",
      "\t√\n",
      "trying: A Frog Wants A Husband.nena\n",
      "\t√\n",
      "trying: A Lost Donkey.nena\n",
      "\t√\n",
      "trying: A Lost Ring.nena\n",
      "\t√\n",
      "trying: A Painting Of The King Of Iran.nena\n",
      "\t√\n",
      "trying: A Pound Of Flesh.nena\n",
      "\t√\n",
      "trying: A Sweater To Pay Off A Debt.nena\n",
      "\t√\n",
      "trying: A Thousand Dinars.nena\n",
      "\t√\n",
      "trying: A Visit From Harun Ar-rashid.nena\n",
      "\t√\n",
      "trying: Agriculture And Village Life.nena\n",
      "\t√\n",
      "trying: Am I Dead?.nena\n",
      "\t√\n",
      "trying: An Orphan Duckling.nena\n",
      "\t√\n",
      "trying: Axiqar.nena\n",
      "\t√\n",
      "trying: Events In 1946 On The Urmi Plain.nena\n",
      "\t√\n",
      "trying: Games.nena\n",
      "\t√\n",
      "trying: Hunting.nena\n",
      "\t√\n",
      "trying: I Have Died.nena\n",
      "\t√\n",
      "trying: Ice For Dinner.nena\n",
      "\t√\n",
      "trying: Is There A Man With No Worries?.nena\n",
      "\t√\n",
      "trying: Kindness To A Donkey.nena\n",
      "\t√\n",
      "trying: Lost Money.nena\n",
      "\t√\n",
      "trying: Mistaken Identity.nena\n",
      "\t√\n",
      "trying: Much Ado About Nothing.nena\n",
      "\t√\n",
      "trying: Nipuxta.nena\n",
      "\t√\n",
      "trying: No Bread Today.nena\n",
      "\t√\n",
      "trying: Problems Lighting A Fire.nena\n",
      "\t√\n",
      "trying: St. Zayya’s Cake Dough.nena\n",
      "\t√\n",
      "trying: Star-crossed Lovers.nena\n",
      "\t√\n",
      "trying: Stomach Trouble.nena\n",
      "\t√\n",
      "trying: The Adventures Of A Princess.nena\n",
      "\t√\n",
      "trying: The Adventures Of Ashur.nena\n",
      "\t√\n",
      "trying: The Adventures Of Two Brothers.nena\n",
      "\t√\n",
      "trying: The Angel Of Death.nena\n",
      "\t√\n",
      "trying: The Assyrians Of Armenia.nena\n",
      "\t√\n",
      "trying: The Assyrians Of Urmi.nena\n",
      "\t√\n",
      "trying: The Bald Child And The Monsters.nena\n",
      "\t√\n",
      "trying: The Bald Man And The King.nena\n",
      "\t√\n",
      "trying: The Bird And The Fox.nena\n",
      "\t√\n",
      "trying: The Cat’s Dinner.nena\n",
      "\t√\n",
      "trying: The Cow And The Poor Girl.nena\n",
      "\t√\n",
      "trying: The Dead Rise And Return.nena\n",
      "\t√\n",
      "trying: The Fisherman And The Princess.nena\n",
      "\t√\n",
      "trying: The Giant One-eyed Demon.nena\n",
      "\t√\n",
      "trying: The Little Prince And The Snake.nena\n",
      "\t√\n",
      "trying: The Loan Of A Cooking Pot.nena\n",
      "\t√\n",
      "trying: The Man Who Wanted To Complain To God.nena\n",
      "\t√\n",
      "trying: The Old Man And The Fish.nena\n",
      "\t√\n",
      "trying: The Purchase Of A Donkey.nena\n",
      "\t√\n",
      "trying: The Snake’s Dilemma.nena\n",
      "\t√\n",
      "trying: The Stupid Carpenter.nena\n",
      "\t√\n",
      "trying: The Wife Who Learns How To Work (2).nena\n",
      "\t√\n",
      "trying: The Wife Who Learns How To Work.nena\n",
      "\t√\n",
      "trying: The Wife’s Condition.nena\n",
      "\t√\n",
      "trying: The Wise Brother.nena\n",
      "\t√\n",
      "trying: The Wise Young Daughter.nena\n",
      "\t√\n",
      "trying: Trickster.nena\n",
      "\t√\n",
      "trying: Two Birds Fall In Love.nena\n",
      "\t√\n",
      "trying: Two Wicked Daughters-in-law.nena\n",
      "\t√\n",
      "trying: Village Life (2).nena\n",
      "\t√\n",
      "trying: Village Life (3).nena\n",
      "\t√\n",
      "trying: Village Life (4).nena\n",
      "\t√\n",
      "trying: Village Life (5).nena\n",
      "\t√\n",
      "trying: Village Life (6).nena\n",
      "\t√\n",
      "trying: Village Life.nena\n",
      "\t√\n",
      "trying: Vineyards.nena\n",
      "\t√\n",
      "trying: Weddings And Festivals.nena\n",
      "\t√\n",
      "trying: Weddings.nena\n",
      "\t√\n",
      "trying: When Shall I Die?.nena\n",
      "\t√\n",
      "trying: Women Are Stronger Than Men.nena\n",
      "\t√\n",
      "trying: Women Do Things Best.nena\n",
      "\t√\n",
      "126 parsed...\n",
      "0 not parsed...\n"
     ]
    }
   ],
   "source": [
    "name2parsed = {}\n",
    "name2text = {}\n",
    "not_parsed = []\n",
    "\n",
    "ignore = [\n",
    "    #'The Adventures Of Two Brothers.nena', # FIX BY MOVING UNEMPHASIZED OUT\n",
    "]\n",
    "\n",
    "for dialect in dialect_dirs:\n",
    "    print(f'--Dialect {dialect}--')\n",
    "    print()\n",
    "    for file in sorted(dialect.glob('*.nena')):\n",
    "        \n",
    "        if file.name in ignore:\n",
    "            print('SKIPPING:', file.name, '\\n')\n",
    "            not_parsed.append(file)\n",
    "            continue\n",
    "        \n",
    "        with open(file, 'r') as infile:\n",
    "            text = infile.read()\n",
    "            name2text[file.name] = text\n",
    "            print(f'trying: {file.name}')\n",
    "            parseit = parser.parse(lexer.tokenize(text))\n",
    "            print(f'\\t√')\n",
    "            name2parsed[file.name] = parseit\n",
    "                \n",
    "print(len(name2parsed), 'parsed...')\n",
    "print(len(not_parsed), 'not parsed...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name2text['A Man Called Čuxo.nena'][7100:7120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Issues (HV)\n",
    "\n",
    "> HV: The parser does not enforce all parts of the grammar. For example, as verse and line breaks are just appended to the trailer, nothing will stop it from adding other trailer elements (save whitespace) after it. *-HV*\n",
    "\n",
    "CK: Unsure of what the problem would be here since trailers can have numerous elements. I will keep an eye on this during the TF conversion. Maybe I will see what you mean.\n",
    "\n",
    "> HV: There is also no check to see whether the two `LANG_MARKER`s have the same value.\n",
    "\n",
    "CK: This should be dealt with at the source text level as a correction. I will watch for such cases.\n",
    "\n",
    "> HV: A `+` sign must appear as the first character in a `morpheme` [in Urmi -CK], but that just means that a `+` in the middle of a morpheme breaks it into two morphemes, instead of invalidating it. Undoubtedly there are more issues like this.\n",
    "\n",
    "I see three such cases:\n",
    "```\n",
    "./Urmi_C/The Snake’s Dilemma.nena:pacúrəl k̭at-nùra⁺bəlláyələˈ ʾu-méša bək̭yàdəl.ˈ ʾu-pacúrəl xa-ʾilána ⁺ràmaˈ\n",
    "./Urmi_C/The Snake’s Dilemma.nena:xlā́p dìyyux,ˈ k̭a⁺tàla márəl,ˈ ʾát m-ìca brílux ⁺ʾal-dá dúca?ˈ m-ìca tpək̭lux\n",
    "./Urmi_C/The Assyrians Of Urmi.nena:(13) ʾíta ʾé ⁺dánəva tìlunˈ ⁺huyyə́rrun k̭a⁺ʾaturáyə k̭át ⁺p̂àlši.ˈ ⁺ʾaturáyə=zə\n",
    "```\n",
    "\n",
    "Since + is treated as a part of the letter (since it functions together with a consonant to convey quality), this problem has been solved. The examples above have been correctly parsed as such (respectively):\n",
    "\n",
    "```\n",
    "<Morpheme 'nùra⁺bəlláyələˈ' trailer ' '>\n",
    "<Morpheme 'k̭a⁺tàla' trailer ' '>\n",
    "<Morpheme 'k̭a⁺ʾaturáyə' trailer ' '>\n",
    "```\n",
    "\n",
    "> HV: Paragraphs in which the first line lacks a `line_id` break the parser. That is true for e.g. the first line of the text in which the `line_id` is absent, or for poetic style text with no `//` verse break marker but with empty line dividing verses. This could (should?) be handled by fixing the issue (default `line_id=1` for first line, default `//` verse break for empty lines within `line`), and issuing a warning notifying the user of the automatic fix.\n",
    "\n",
    "CK: This is now treated at the source in the corrections script. \n",
    "\n",
    "> HV: Footnotes can only be one line and the string is not processed (e.g. markup like `*emphasis*` is kept as is).\n",
    "\n",
    "CK: The multiline issue is now solved in the parser. I will mark the missing emphasis in issues to be dealt with later. I consider footnotes an extra feature.\n",
    "\n",
    "> HV: Footnote anchors can now only occur after a `morpheme`, not after other things like `comment` or `interruption`. (note to self: possible solution: include `fn_anc` in `morphemes` instead of `morpheme_trailer`, and put `comment` in `trailer`).\n",
    "\n",
    "CK: Solved in the parser.\n",
    "\n",
    "> HV: Comments and unreferenced footnotes are returned as tuples for now, and have to be filtered out in the loop.\n",
    "\n",
    "This is a good solution for the time being, since the TF conversion script can take it or leave it.\n",
    "\n",
    "### Questions (HV)\n",
    "\n",
    "Some questions require answers for implementation. They need not be definitive answers for now, but they should be motivated somehow (even if the motivation is 'random choice'), so it will be clear later why it is done in one way or another.\n",
    "\n",
    "- How to store hyphen? Now it is stored as a character in a word occuring between morphemes (I think).\n",
    "  \n",
    "  Should it be the trailer of the morpheme?\n",
    "\n",
    "- How to split sentences?\n",
    "\n",
    "  Now sentences are split on .?! and subsentences on ,\n",
    "  There are other symbols: ;:– and even .. ... ..., .... ..... (If I recall correctly). Should those split\n",
    "  sentences or subsentences?\n",
    "\n",
    "\n",
    "- What to do with poetic line breaks and sentence/paragraph boundaries?\n",
    "\n",
    "  I think a 'poem' should not be divided into paragraphs. I suggest that a line break '/' is a subsentence division, and a verse break '//' a sentence division (even when in the source it is followed by an empty line). If there is a verse number in between, that automatically starts a new sentence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
