{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with the Text Fabric corpora of Barwar and Christian Urmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Barwar and Christian Urmi (Urmi_C) corpora converted from Word format to Text Fabric, we can perform all kinds of analyses on the texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.8.0\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "13 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations='tf/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.01s B otype                from tf\n",
      "   |     0.00s Not enough info for sections in otext, section functionality will not work\n",
      "   |     0.00s Not enough info for structure in otext, structure functionality will not work\n",
      "   |     0.15s B char                 from tf\n",
      "   |     0.00s B text_id              from tf\n",
      "   |     0.00s B line                 from tf\n",
      "   |     0.00s B title                from tf\n",
      "   |     0.00s B dialect              from tf\n",
      "   |     0.00s B filename             from tf\n",
      "  2.01s All features loaded/computed - for details use loadLog()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N = TF.load('''\n",
    "\n",
    "text_id paragraph line word char otype title dialect filename\n",
    "\n",
    "''')\n",
    "\n",
    "N.makeAvailableIn(globals())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus is divided into texts. Texts are divided in paragraphs, (numbered) lines, sentences, subsentences, words, morphemes, and finally characters.\n",
    "\n",
    "Paragraphs are units of text that are separated by a newline character in the Word files. Lines are units that start with a line (or verse) number in round brackets. Sentences are units of text that are terminated by a period (full stop) character, an exclamation mark or a question mark. Subsentences divided by a comma. Words are separated by whitespace or punctuation. Morphemes are parts of words separated by single or double hyphens. Characters are any letter, possibly combined with combining diacritics, or any other character symbol.\n",
    "\n",
    "These definitions do not necessarily conincide with accepted linguistic terms. For example, what is here called a 'morpheme' may be a word composed of several morphemes, but for the sake of simplification we use the term here for separated parts of a word. A word is a group of syllables with one stress marker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a look at a text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 730893: A14 TALES FROM THE 1001 NIGHTS\n",
      "\n",
      "731561 xa-màlka| kút-yum ðà-brata gawə́rwa.| mbádla qayə́mwa qaṭə̀lwala.| wăzī̀r| xðírre xðìrre,| bnáθa prìqla.| kút-yum ðà,| lìθ.| ʾáwwa wăzī́r ʾíθwale ða-bràta.| ʾa-bráta mə́ra ṭla-wằzir,| ṭla-bába dìya,| mə́ra bábi ʾána nàbəlli| gawrànne ʾáwwa málka| mparqànnux m-áyya qə́ṣṣət.|\n",
      "731562 qìmtɛla| ʾítwala ða-qàṭu,| nubàltəlla mə́nna díya.| nubáltəlla qáṭu mə́nna dìya,| gwìrtəlle málka.| ʾaw-dmìxɛle,| píštɛla mtanóye ða-qə̀ṣṣət| ṭla-qàṭu.|\n"
     ]
    }
   ],
   "source": [
    "text = F.otype.s('text')[0]\n",
    "print(f'Text {text}: {F.text_id.v(text)} {F.title.v(text)}\\n')\n",
    "\n",
    "for line in F.otype.s('line')[:2]:\n",
    "    print(line, T.text(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I find it cumbersome to refer to otypes and nodes while navigating a text,\n",
    "I wrote a small class to provide a more object-oriented interface to the texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, node):\n",
    "        self.node = node\n",
    "        self.otype = F.otype.v(node)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'<Node {self.node} otype {repr(self.otype)}>'\n",
    "        \n",
    "    def __str__(self):\n",
    "        return T.text(self.node)\n",
    "        \n",
    "    def __getattr__(self, name):\n",
    "        # first try to give the value of a feature called `name`\n",
    "        if hasattr(F, name):\n",
    "            f = getattr(F, name)\n",
    "            if self.node in f.data:\n",
    "                return f.v(self.node)\n",
    "            # if node does not have feature, try embedding nodes\n",
    "            else:\n",
    "                for node in L.u(self.node):\n",
    "                    if node in f.data:\n",
    "                        return f.v(node)\n",
    "        # check for upward embedding node of otype `name`\n",
    "        n = L.u(self.node, name)\n",
    "        if len(n):  # in case of multiple embedding nodes of otype `name`, return first one\n",
    "            return Node(n[0])\n",
    "        # if nothing is returned, try looking for embedded nodes        \n",
    "        if name.endswith('s'): # if name has plural form, look for otype of `name` minus 's'\n",
    "            # try to give generator of downward Nodes of otype `name`\n",
    "            # TODO how to check if self.otype has downward nodes of otype `name`?\n",
    "            return [Node(n) for n in L.d(self.node, name[:-1])]\n",
    "        else:\n",
    "            raise AttributeError(f'Otype {self.otype} has no attribute {name}.')\n",
    "    \n",
    "    @property\n",
    "    def text(self):  # make text() a property method to keep it lazy\n",
    "        return str(self)\n",
    "            \n",
    "\n",
    "def nodelist(otype):\n",
    "    return [Node(n) for n in F.otype.s(otype)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a list of all texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = nodelist('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Node 730893 otype 'text'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TALES FROM THE 1001 NIGHTS'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730893"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xa-màlka| kút-yum ðà-brata gawə́rwa.| mbádla qayə́mwa qaṭə̀lwala.| wăzī̀r| xðírre xðìrre,| bnáθa prìqla.| kút-yum ðà,| lìθ.| ʾáwwa wăzī́r ʾíθwale ða-bràta.| ʾa-bráta mə́ra ṭla-wằzir,| ṭla-bába dìya,| mə́ra bábi ʾána nàbəlli| gawrànne ʾáwwa málka| mparqànnux m-áyya qə́ṣṣət.|qìmtɛla| ʾítwala ða-qàṭu,| nubàltəlla mə́nna díya.| nubáltəlla qáṭu mə́nna dìya,| gwìrtəlle málka.| ʾaw-dmìxɛle,| píštɛla mtanóye ða-qə̀ṣṣət| ṭla-qàṭu.|mə́ra ṭla-d-à-q ...'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].text[:500] + ' ...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 xa-màlka| kút-yum ðà-brata gawə́rwa.| mbádla qayə́mwa qaṭə̀lwala.| wăzī̀r| xðírre xðìrre,| bnáθa prìqla.| kút-yum ðà,| lìθ.| ʾáwwa wăzī́r ʾíθwale ða-bràta.| ʾa-bráta mə́ra ṭla-wằzir,| ṭla-bába dìya,| mə́ra bábi ʾána nàbəlli| gawrànne ʾáwwa málka| mparqànnux m-áyya qə́ṣṣət.|\n"
     ]
    }
   ],
   "source": [
    "print(texts[0].lines[0].line, texts[0].lines[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barwar A14 TALES FROM THE 1001 NIGHTS bar text A14.html\n",
      "xa-màlka| kút-yum ðà-brata gawə́rwa.| mbádla qayə́mwa qaṭə̀lwala.| wăzī̀r| xðírre xðìrre,| bnáθa prìqla.| kút-yum ðà,| lìθ.| ʾáwwa wăzī́r ʾíθwale ða-bràta.| ʾa-bráta mə́ra ṭla-wằzir,| ṭla-bába dìya,| mə́ra bábi ʾána nàbəlli| gawrànne ʾáwwa málka| mparqànnux m-áyya qə́ṣṣət.|\n"
     ]
    }
   ],
   "source": [
    "line = texts[0].lines[0]\n",
    "print(line.dialect, line.text_id, line.title, line.filename)\n",
    "print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate that units like paragraph, line, sentence, etc. are not strictly hierarchical, we will take as an example a poetic text, Barwar A49 *The crow and the cheese* (note -- finding the text may actually be more convenient through the TF search functions, than with a list comprehension):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "barwar_a49 = [t for t in texts if t.dialect == 'Barwar' and t.text_id == 'A49'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE CROW AND THE CHEESE\n",
      "Paragraphs: 23\n",
      "Lines: 6\n"
     ]
    }
   ],
   "source": [
    "print(barwar_a49.title)\n",
    "print('Paragraphs:', len(barwar_a49.paragraphs))\n",
    "print('Lines:', len(barwar_a49.lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where most `paragraph`s contain one or more `line`s, here the number of lines is lower than the number of paragraphs. When we print them below each other, we can see why:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 qarə́kke ṱ-íla kùmta|   xá-yoma ʾay-tìwta| l-ʾilána b-púmma gùpta| \n",
      "2 θéle téla pandàna| mtuxmə́nne ṱ-áwəð nxìlθa| ṭla-madréla b-xerə̀tta| šaqə́lla mə́nna gùpta| \n",
      "3 mə́re ʾən-qáləx mdáme ʾə̀lləx| xa-xéna lit-daxwàθəx| \n",
      "4 qíx qréla b-gáwət qàla| gúpta mən-púmma npìlla| téla mo-ṭréle ʾə̀lla!| \n",
      "5 šeðánta qəm-šaqə̀lla| qəm-ʾaryála pəšmànta| \n",
      "6 téla mə́re šeðànta| la-mháymnət kul-maxkɛ́θa basìmta| téla mére šeðànta| la-mháymnət kul-maxkɛ́θa basìmta|\n",
      "\n",
      "(1)  qarə́kke ṱ-íla kùmta|  \n",
      "     xá-yoma ʾay-tìwta|\n",
      "     l-ʾilána b-púmma gùpta|\n",
      "     \n",
      "(2)  θéle téla pandàna|\n",
      "     mtuxmə́nne ṱ-áwəð nxìlθa|\n",
      "     ṭla-madréla b-xerə̀tta|\n",
      "     šaqə́lla mə́nna gùpta|\n",
      "     \n",
      "(3)  mə́re ʾən-qáləx mdáme ʾə̀lləx|\n",
      "     xa-xéna lit-daxwàθəx|\n",
      "     \n",
      "(4)  qíx qréla b-gáwət qàla|\n",
      "     gúpta mən-púmma npìlla|\n",
      "     téla mo-ṭréle ʾə̀lla!|\n",
      "     \n",
      "(5)  šeðánta qəm-šaqə̀lla|\n",
      "     qəm-ʾaryála pəšmànta|\n",
      "     \n",
      "(6)  téla mə́re šeðànta|\n",
      "     la-mháymnət kul-maxkɛ́θa basìmta|\n",
      "     téla mére šeðànta|\n",
      "     la-mháymnət kul-maxkɛ́θa basìmta|\n"
     ]
    }
   ],
   "source": [
    "for line in barwar_a49.lines:\n",
    "    print(line.line, line)\n",
    "\n",
    "print()\n",
    "\n",
    "for line in barwar_a49.lines:\n",
    "    print(f'({line.line}) ', '\\n    '.join([p.text for p in line.paragraphs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textual problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding the `+` as a word character, besides regular letter characters, the number of `morphemes` dropped from 120141 to 120134. The cause turned out to be that several `morphemes` contain a `+` character at a non-word-initial position.\n",
    "\n",
    "Three possible causes:\n",
    "- the `+` is accidentily placed after initial alaph;\n",
    "- a space is omitted between two `words`, the second one with initial `+`;\n",
    "- a hyphen is omitted between two `morphemes`, the second one with initial `+`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120134\n"
     ]
    }
   ],
   "source": [
    "morphemes = nodelist('morpheme')\n",
    "print(len(morphemes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urmi_C cu vol 4 texts.html A 1 38 'ʾ+átrət'\n",
      "Urmi_C cu vol 4 texts.html A3 53 'ʾəhtiyɑ̄̀j+ʾallux'\n",
      "Urmi_C cu vol 4 texts.html A4 10 'ʾ+òtax'\n",
      "Urmi_C cu vol 4 texts.html A47 1 'nùra+bəlláyələ'\n",
      "Urmi_C cu vol 4 texts.html A47 16 'k̭a+tàla'\n",
      "Urmi_C cu vol 4 texts.html B1 13 'k̭a+ʾaturáyə'\n",
      "Urmi_C cu vol 4 texts.html B5 3 'ʾ+al'\n"
     ]
    }
   ],
   "source": [
    "morphemes = nodelist('morpheme')\n",
    "\n",
    "# this search using python string operators is slow.\n",
    "# maybe TF has builtin string search capabilities which are faster?\n",
    "for m in [m for m in morphemes if m.text[0] != '+' and '+' in m.text]:\n",
    "    print(m.dialect, m.filename, m.text_id, m.line, repr(m.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not unlikely that there are more cases where spaces or hyphens are omitted.\n",
    "\n",
    "A way to check this could be to look at the stress markers (`acute accent` and `grave accent`), which should occur once in each `word`. That would lead to the conclusion that in `ʾəhtiyɑ̄̀j+ʾallux`, `k̭a+tàla`, `k̭a+ʾaturáyə`, a hyphen is missing, whereas in `nùra+bəlláyələ` a space is omitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that every word does indeed need exactly one stress marker, any word with no or multiple stress markers is a mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for words with no or multiple stress markers\n",
    "words = nodelist('word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words with no stress markers: 716\n",
      "Example: Barwar 'bar text A14.html' A14:8 'Kărīm-addīn'\n"
     ]
    }
   ],
   "source": [
    "no_stress = [w for w in words if not ('\\u0300' in str(w) or '\\u0301' in str(w))]\n",
    "\n",
    "print('Number of words with no stress markers:', len(no_stress))\n",
    "w = no_stress[0]\n",
    "print('Example:', w.dialect, repr(w.filename), f'{w.text_id}:{w.line}', repr(w.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words with multiple stress markers: 97\n",
      "Example: Barwar 'bar text a29.html' A29:20 'hó-b-ʾíðe'\n"
     ]
    }
   ],
   "source": [
    "multiple_stress = [w for w in words if len([c for c in w.chars if '\\u0300' in str(c) or '\\u0301' in str(c)]) > 1]\n",
    "\n",
    "print('Number of words with multiple stress markers:', len(multiple_stress))\n",
    "w = multiple_stress[0]\n",
    "print('Example:', w.dialect, repr(w.filename), f'{w.text_id}:{w.line}', repr(w.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the total number of words with no or multiple stress markers is apparently 813, it will be quite a challenge to check them for omitted spaces or hyphens, especially as in most cases it may not be clear what should be the correct form."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
