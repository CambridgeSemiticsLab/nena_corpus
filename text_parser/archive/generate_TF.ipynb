{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Text-Fabric Resource from Source Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing for Christian Urmi and Barwar texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with the language data in the NENA corpus, it is important to separate the language text from other data, such as titles, authors/informants, and verse numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our version of the text comes in MS-Word document files. That is probably also the version of the text that is the richest in language data. It contains not only the text itself, but also meaningful formatting, e.g. word markers set in superscript, and foreign (loan) words set in roman type (where the regular text is set in italic type)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert that information from a Word document to something that we can use in Python, we first convert the word documents to HTML, using LibreOffice in headless mode. It is assumed that the Word files are in the subdirectory `texts`, where the converted `.html` files will also be saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    $ soffice --headless --convert-to html texts/*.doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This produces HTML 4.0 documents in the same directory. Earlier attempts with XHTML using wvWare/AbiWord, or LibreOffice using the XHTML conversion filter, produced output that was more difficult to parse or lacked certain characters that were lost in conversion. Although the conversion with LibreOffice takes a very long time compared with AbiWord, the resulting text seems more reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom `nena_corpus` package contains the `Text` class, and several functions that assist in the conversion from HTML, of which we only need the functions `html_to_text()` and `parse_metadata()`.\n",
    "\n",
    "The function `html_to_text()` is a generator function yielding `Text` objects, each containing one paragraph of text.\n",
    "\n",
    "The function `parse_metadata()` extracts metadata from heading paragraphs (e.g. `title`, `text_id`, `informant`, `place`).\n",
    "\n",
    "The `Text` class contains an attribute `type` describing the type of paragraph (e.g., `'sectionheading'`, `'p'`, or `'footnote'`), and a list of tuples, containing the text and text style. A text like `'<i>Normal, </i>foreign<i>, and normal</i>'` becomes `[('Normal, ', ''), ('cursive,', 'italic'), (' and normal', '')]` (note the inversion -- because normal text in the source is actually set in italics).\n",
    "\n",
    "`Text` objects are iterable. New items can be appended with the `append(text, text_style)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nena_corpus import Text, html_to_text, parse_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small demonstration of the `Text` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dit is een test.\n",
      "<Text 'test' 'Dit is een test.'>\n",
      "[('Dit is ', 'normal'), ('een test', 'test'), ('.', 'normal')]\n",
      "[('Dit is ', 'normal'), ('een test', 'test'), ('.', 'normal')]\n"
     ]
    }
   ],
   "source": [
    "p = Text(p_type='test', default_style='normal')\n",
    "\n",
    "p.append('Dit is ')\n",
    "p.append('een test', 'test')\n",
    "p.append('.')\n",
    "\n",
    "# str(p) returns concatenated string\n",
    "print(p)\n",
    "# repr(p) returns class name, p_type and str(p)\n",
    "print(repr(p))\n",
    "# list(p) returns the list of tuples\n",
    "print(list(p))\n",
    "# a list comprehension also works\n",
    "print([e for e in p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import some more useful libraries, and set logging level to DEBUG to make sure we see all logging messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import pathlib\n",
    "import logging\n",
    "import unicodedata\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from tf.fabric import Fabric\n",
    "import pandas as pd\n",
    "\n",
    "logging.getLogger().setLevel(logging.DEBUG) # for terminal messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that the subdirectory `texts` contains the HTML files generated earlier, we can import all files in the pattern `texts/*.html`. At this point we just want to do language statistics and not look at the actual texts, so it is sufficient to import the paragraphs of all texts in no particular order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_barwar = pathlib.Path.cwd().glob('texts/bar text *.html') # get source texts\n",
    "files_urmi_c = pathlib.Path.cwd().glob('texts/cu *.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also prepare a dictionary with some characters that need to be replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characters to be replaced\n",
    "replace = {\n",
    "    '\\u2011': '\\u002d',  # U+2011 NON-BREAKING HYPHEN -> U+002D HYPHEN-MINUS\n",
    "    '\\u01dd': '\\u0259',  # U+01DD LATIN SMALL LETTER TURNED E -> U+0259 LATIN SMALL LETTER SCHWA\n",
    "    '\\uf1ea': '\\u003d',  # U+F1EA Deprecated SIL character -> U+003D '=' EQUALS SIGN\n",
    "    '\\u2026': '...',  # U+2026 '…' HORIZONTAL ELLIPSIS -> three dots\n",
    "    'J\\u0335': '\\u0248',  # 'J' + U+0335 COMBINING SHORT STROKE OVERLAY -> U+0248 'Ɉ' LATIN CAPITAL LETTER J WITH STROKE\n",
    "    'J\\u0336': '\\u0248',  # 'J' + U+0336 COMBINING LONG STROKE OVERLAY -> U+0248 'Ɉ' LATIN CAPITAL LETTER J WITH STROKE\n",
    "    '\\u002d\\u032d': '\\u032d\\u002d',  # Switch positions of Hyphen and Circumflex accent below\n",
    "    '\\u2011\\u032d': '\\u032d\\u002d',  # Switch positions of Non-breaking hyphen and Circumflex accent below\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we go right ahead to loop over the html files and convert them to a TextFabric structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing file bar text a15-A17.html ...\n",
      "INFO:root:Processing file bar text A45.html ...\n",
      "INFO:root:Processing file bar text a28.html ...\n",
      "INFO:root:Processing file bar text A49.html ...\n",
      "INFO:root:Processing file bar text a24.html ...\n",
      "DEBUG:root:Unhandled paragraph type: 'footer'.\n",
      "DEBUG:root:Text: ' 7 '.\n",
      "INFO:root:Processing file bar text A42-A44.html ...\n",
      "INFO:root:Processing file bar text a25.html ...\n",
      "INFO:root:Processing file bar text a48.html ...\n",
      "DEBUG:root:Unhandled paragraph type: 'footer'.\n",
      "DEBUG:root:Text: ' 1 '.\n",
      "INFO:root:Processing file bar text a29.html ...\n",
      "INFO:root:Processing file bar text A9-A13.html ...\n",
      "INFO:root:Processing file bar text a46-A47.html ...\n",
      "INFO:root:Processing file bar text A37-A40.html ...\n",
      "INFO:root:Processing file bar text a18.html ...\n",
      "INFO:root:Processing file bar text a1-A7.html ...\n",
      "DEBUG:root:Unhandled paragraph type: 'sdfootnote1'.\n",
      "DEBUG:root:Text: ' 1 The name Čuxo means ‘one who wears the woolen čuxa garment’. '.\n",
      "INFO:root:Processing file bar text a34.html ...\n",
      "INFO:root:Processing file bar text A14.html ...\n",
      "INFO:root:Processing file bar text a35.html ...\n",
      "INFO:root:Processing file bar text a36.html ...\n",
      "INFO:root:Processing file bar text a41.html ...\n",
      "INFO:root:Processing file bar text a8.html ...\n",
      "INFO:root:Processing file bar text a19-A23.html ...\n",
      "INFO:root:Processing file bar text a26.html ...\n",
      "INFO:root:Processing file bar text a30.html ...\n",
      "INFO:root:Processing file bar text a31-A33.html ...\n",
      "INFO:root:Processing file bar text a50-A52.html ...\n",
      "INFO:root:Processing file bar text a27.html ...\n",
      "INFO:root:Processing file cu vol 4 texts.html ...\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text: ' '.\n",
      "WARNING:root:Unfinished marker: 'R', closed forcibly..\n",
      "DEBUG:root:Urmi_C, A43:17\n",
      "DEBUG:root:Text: ' várdə=da mattúvvəla k̭am-bràto.| ʾáxči cálu labùlola.| +p̂urmìlux k̭a-díyyi?| lublàlun,| lublàlun,| lublàlun,| lublàlun.|'\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text: ' '.\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text: ' '.\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text: ' '.\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text: ' '.\n",
      "DEBUG:root:Unhandled paragraph type: 'gp-sectionheading-western'.\n",
      "DEBUG:root:Text: ' '.\n",
      "DEBUG:root:Unhandled paragraph type: 'sdfootnote1'.\n",
      "DEBUG:root:Text: ' 1 In the original recording of the story the speaker used the word camra ‘animal droppings’ here, but subsequently corrected this to calla. '.\n",
      "DEBUG:root:Unhandled paragraph type: 'sdfootnote2'.\n",
      "DEBUG:root:Text: ' 2 Mistake for šənnə +xarayə. '.\n",
      "DEBUG:root:Unhandled paragraph type: 'footer'.\n",
      "DEBUG:root:Text: ' 189 '.\n"
     ]
    }
   ],
   "source": [
    "def combine_chars(text):\n",
    "    \"\"\"Yield letters combined with combining diacritics\"\"\"\n",
    "    \n",
    "    char = [] # compose string here: letter + diacritic\n",
    "    \n",
    "    for c in text:\n",
    "        \n",
    "        # add diacritic\n",
    "        # indicated as 'Mn': non-spacing combining mark\n",
    "        if unicodedata.category(c) == 'Mn':\n",
    "            char.append(c)\n",
    "            continue\n",
    "        \n",
    "        # yield the string; at this point will be: letter + (diacritic)\n",
    "        if char:\n",
    "            yield ''.join(char)\n",
    "            \n",
    "        char = [c] # save in list and get diacritic next if there is one\n",
    "        \n",
    "    yield ''.join(char) # yield empty chars\n",
    "\n",
    "# keep object counts\n",
    "raw_features = collections.defaultdict(lambda:collections.defaultdict(set))\n",
    "raw_oslots = collections.defaultdict(lambda:collections.defaultdict(set))\n",
    "\n",
    "# initialize counters (will be increased to start from 1)\n",
    "this_dialect = 0\n",
    "this_text = 0\n",
    "this_paragraph = 0\n",
    "this_line = 0\n",
    "this_sentence = 0\n",
    "this_subsentence = 0\n",
    "this_word = 0\n",
    "this_morpheme = 0\n",
    "this_foreign = 0\n",
    "this_prosa = 0\n",
    "\n",
    "slot = 0 # i.e. chars\n",
    "\n",
    "process_dialects = {'Barwar': files_barwar,\n",
    "                    'Urmi_C': files_urmi_c}\n",
    "\n",
    "text_ids = []\n",
    "\n",
    "for dialect, files in process_dialects.items():\n",
    "    \n",
    "    # TODO At this point record book/publication/dialect?\n",
    "    # E.g. SSLL_2016_Urmi_C, HOS_2008_Barwar?\n",
    "    \n",
    "    # add dialect object\n",
    "    this_dialect += 1\n",
    "    raw_features['dialect'][this_dialect] = dialect\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        logging.info(f'Processing file {file.name} ...')\n",
    "        \n",
    "        for p in html_to_text(file, replace=replace):\n",
    "            # metadata:\n",
    "            # - dialect\n",
    "            # - file.name\n",
    "            \n",
    "            if p.type.startswith('gp-') and str(p).strip():\n",
    "                # store metadata from headings:\n",
    "                # - text_id\n",
    "                # - title\n",
    "                # - informant\n",
    "                # - place\n",
    "                # - version (if applicable -- only Urmi_C A35)\n",
    "                if p.type.startswith('gp-sectionheading'):\n",
    "                    metadata = {}\n",
    "                for k, v in parse_metadata(p):\n",
    "                    metadata[k] = v\n",
    "            \n",
    "            elif p.type == 'p':\n",
    "                # regular paragraphs\n",
    "                \n",
    "                # format a text_id with version added (if there is one)\n",
    "                version = metadata.get('version', '')\n",
    "                version = f'.{version[-1]}' if version else ''\n",
    "                text_id = metadata.get('text_id', '') + version\n",
    "                \n",
    "                # first check if we need to update metadata\n",
    "                # informant and place are also added as features of text\n",
    "                if (metadata\n",
    "                    and (not raw_features['text_id']\n",
    "                         or raw_features['text_id'][this_text] != text_id)):\n",
    "                        \n",
    "                        \n",
    "                    text_ids.append(text_id)\n",
    "                        \n",
    "                    this_text += 1\n",
    "                    raw_features['text_id'][this_text] = text_id\n",
    "                    raw_features['title'][this_text] = metadata['title']\n",
    "                    raw_features['informant'][this_text] = metadata['informant']\n",
    "                    raw_features['place'][this_text] = metadata['place']\n",
    "                    raw_features['dialect'][this_text] = dialect\n",
    "                    raw_features['filename'][this_text] = file.name\n",
    "                \n",
    "                # increment paragraph\n",
    "                this_paragraph += 1\n",
    "                \n",
    "                # start paragraph with an empty marker stack\n",
    "                marker_stack = []\n",
    "                \n",
    "                # set end-of-unit markers to True at the beginning of paragraph,\n",
    "                # so the units can be increased on encounter of first word character\n",
    "                sentence_end = True\n",
    "                subsentence_end = True\n",
    "                word_end = True\n",
    "                morpheme_end = True\n",
    "                foreign_end = True\n",
    "                prosa_end = True\n",
    "                \n",
    "                for text, text_style in p:\n",
    "                    \n",
    "                    if text_style == 'verse_no':\n",
    "                        this_line += 1\n",
    "                        raw_features['line'][this_line] = text.strip(' ()') # TODO int()?\n",
    "                        metadata['verse_no'] = text.strip(' ()')  # TODO Remove from metadata dict?\n",
    "                        continue\n",
    "                        \n",
    "                    elif text_style == 'fn_anchor':\n",
    "                        # TODO handle footnotes in some way, discard for now\n",
    "                        continue\n",
    "                    \n",
    "                    elif text_style == 'comment':\n",
    "                        continue  # TODO handle comments\n",
    "                    \n",
    "                    elif text_style == 'marker':\n",
    "                        if marker_stack and marker_stack[-1] == text:\n",
    "                            marker_stack.pop()\n",
    "                        else:\n",
    "                            marker_stack.append(text)\n",
    "                        continue\n",
    "                    \n",
    "                    elif text_style not in ('', 'foreign'):\n",
    "                        logging.debug(f'Unhandled text_style: {repr(text_style)}, {repr(text)}')\n",
    "                        continue\n",
    "                    \n",
    "                    elif text_style == 'foreign' and foreign_end:\n",
    "                        foreign_end = False\n",
    "                        if marker_stack:\n",
    "                            language = marker_stack[-1]\n",
    "                        else:\n",
    "                            language = ''\n",
    "                    \n",
    "                    else: # text_style == '':\n",
    "                        if not foreign_end:\n",
    "                            foreign_end = True\n",
    "                        pass\n",
    "                    \n",
    "                    if (text_style == '' and marker_stack\n",
    "                        and any(c.isalpha() for c in text)\n",
    "                        and not text.isalpha()):\n",
    "                        # In one case, there is no closing marker tag, so force closing the marker\n",
    "                        # Urmi_C A42 9: 'RzdànyəlaR' (p.154, r.28) 'zdàny' roman, 'əla' cursive\n",
    "                        # Urmi_C A43 17: 'ʾe-Rbuk̭ḗṱ' (p. 174, r.14), no closing 'R'\n",
    "                        # Urmi_C B2 16: 'Pʾafšɑ̄rī̀P' (p.250 r.17), inital 'ʾ' cursive\n",
    "                        marker = marker_stack.pop()\n",
    "                        logging.warning(f'Unfinished marker: {repr(marker)}, closed forcibly..')\n",
    "                        logging.debug(f'{dialect}, {metadata[\"text_id\"]}:{metadata[\"verse_no\"]}')\n",
    "                        logging.debug(f'Text: {repr(text)}')\n",
    "                    \n",
    "                    # If we got this far, we have a text string,\n",
    "                    # with either text_style '' or 'foreign'.\n",
    "                    # We will iterate over them character by character.\n",
    "                    for c in combine_chars(text):\n",
    "                        \n",
    "                        if c[0].isalpha() or c == '+':\n",
    "                            \n",
    "                            # Increment text units on start of new word\n",
    "                            if morpheme_end:\n",
    "                                this_morpheme += 1\n",
    "                                morpheme_end = False\n",
    "                            if word_end:\n",
    "                                this_word += 1\n",
    "                                word_end = False\n",
    "                            if subsentence_end:\n",
    "                                this_subsentence += 1\n",
    "                                subsentence_end = False\n",
    "                            if sentence_end:\n",
    "                                this_sentence += 1\n",
    "                                sentence_end = False\n",
    "                            if prosa_end:\n",
    "                                this_prosa += 1\n",
    "                                prosa_end = False\n",
    "                            \n",
    "                            slot += 1\n",
    "                            \n",
    "                            pretty_c = unicodedata.normalize('NFC', c) # make pretty utf8 char text\n",
    "                                      \n",
    "                            raw_features['utf8'][slot] = pretty_c\n",
    "                            # initialize 'trailer' feature as empty string,\n",
    "                            # so we can add characters with '+' operator later\n",
    "                            raw_features['trailer'][slot] = ''\n",
    "                                      \n",
    "                            # add foreign feature here\n",
    "                            if not foreign_end:\n",
    "                                raw_features['language'][slot] = language\n",
    "                            \n",
    "                            raw_oslots['dialect'][this_dialect].add(slot)\n",
    "                            raw_oslots['text'][this_text].add(slot)\n",
    "                            raw_oslots['paragraph'][this_paragraph].add(slot)\n",
    "                            raw_oslots['line'][this_line].add(slot)\n",
    "                            raw_oslots['sentence'][this_sentence].add(slot)\n",
    "                            raw_oslots['subsentence'][this_subsentence].add(slot)\n",
    "                            raw_oslots['prosa'][this_prosa].add(slot)\n",
    "                            if not word_end:\n",
    "                                raw_oslots['word'][this_word].add(slot)\n",
    "                            if not morpheme_end:\n",
    "                                raw_oslots['morpheme'][this_morpheme].add(slot)\n",
    "                        \n",
    "                        else:  # if c is anything but a letter or '+':\n",
    "                            if slot == 0:\n",
    "                                continue  # discard anything before first word character\n",
    "                            if not morpheme_end:\n",
    "                                morpheme_end = True\n",
    "                            if c == '|':\n",
    "                                prosa_end = True\n",
    "                                c = '\\u02c8'\n",
    "                            if c not in ('-', '=') and not word_end:\n",
    "                                word_end = True\n",
    "                            if c == ',' and not subsentence_end:\n",
    "                                subsentence_end = True\n",
    "                            if c in ('.', '!', '?') and not sentence_end:\n",
    "                                subsentence_end = True\n",
    "                                sentence_end = True\n",
    "                            \n",
    "                            raw_features['trailer'][slot] += c\n",
    "                \n",
    "            else:\n",
    "                logging.debug(f'Unhandled paragraph type: {repr(p.type)}.')\n",
    "                logging.debug(f'Text: {repr(str(p))}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindex Objects Above Slot Levels\n",
    "\n",
    "We have given all objects a preliminary node number. Now those node numbers will be renumbered starting from the max slot number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "otype2feature = {\n",
    "    'dialect':{'dialect'},\n",
    "    'text': {'text_id', 'title', 'dialect', 'filename', 'informant', 'place'},\n",
    "    'paragraph': {},\n",
    "    'line': {'line'},\n",
    "    'sentence': {},\n",
    "    'subsentence': {},\n",
    "    'word': {'trailer'},\n",
    "    'morpheme': {},\n",
    "    'prosa': {},\n",
    "}\n",
    "\n",
    "onode = max(raw_features['utf8']) # max slot, incremented +1 in loop\n",
    "node_features = collections.defaultdict(lambda:collections.defaultdict())\n",
    "edge_features = collections.defaultdict(lambda:collections.defaultdict(set)) # oslots will go here\n",
    "\n",
    "# first add slot features\n",
    "# object features must then be added with otype2feature\n",
    "node_features['utf8'] = raw_features['utf8']\n",
    "node_features['trailer'] = raw_features['trailer']\n",
    "node_features['language'] = raw_features['language']\n",
    "\n",
    "# add slot object types\n",
    "for slot in node_features['utf8']:\n",
    "    node_features['otype'][slot] = 'char'    \n",
    "    \n",
    "# for objects above slot level, \n",
    "# assign new node number and link to feature\n",
    "for otype in raw_oslots.keys():\n",
    "    for oID, slots in raw_oslots[otype].items():\n",
    "        \n",
    "        # make new object node number\n",
    "        onode += 1\n",
    "        node_features['otype'][onode] = otype\n",
    "        \n",
    "        # remap node features to node number\n",
    "        for feat in otype2feature[otype]:\n",
    "            node_features[feat][onode] = raw_features[feat][oID]\n",
    "        edge_features['oslots'][onode] = raw_oslots[otype][oID]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following features are logged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['utf8', 'trailer', 'language', 'otype', 'dialect', 'title', 'text_id', 'informant', 'place', 'filename', 'line'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following edges are logged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['oslots'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_features.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purge Old TF Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in pathlib.Path.cwd().glob('tf/?*.tf'):\n",
    "    file.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save New TF Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.8.5\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "0 features found and 0 ignored\n",
      "  0.00s Warp feature \"otype\" not found in\n",
      "tf//\n",
      "  0.01s Warp feature \"oslots\" not found in\n",
      "tf//\n",
      "  0.01s Warp feature \"otext\" not found. Working without Text-API\n",
      "\n",
      "  0.00s Exporting 11 node and 1 edge and 2 config features to tf/:\n",
      "  0.00s VALIDATING oslots feature\n",
      "  0.09s VALIDATING oslots feature\n",
      "  0.09s maxSlot=     551014\n",
      "  0.09s maxNode=     845338\n",
      "  0.14s OK: oslots is valid\n",
      "   |     0.00s T dialect              to tf\n",
      "   |     0.00s T filename             to tf\n",
      "   |     0.00s T informant            to tf\n",
      "   |     0.01s T language             to tf\n",
      "   |     0.01s T line                 to tf\n",
      "   |     0.23s T otype                to tf\n",
      "   |     0.00s T place                to tf\n",
      "   |     0.00s T text_id              to tf\n",
      "   |     0.00s T title                to tf\n",
      "   |     0.80s T trailer              to tf\n",
      "   |     0.71s T utf8                 to tf\n",
      "   |     1.20s T oslots               to tf\n",
      "   |     0.00s M otext                to tf\n",
      "   |     0.00s M paragraph            to tf\n",
      "  3.11s Exported 11 node features and 1 edge features and 2 config features to tf/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otext = {\n",
    "    'sectionTypes': 'dialect,text,line',\n",
    "    'sectionFeatures': 'dialect,title,line',\n",
    "    'fmt:text-orig-full': '{utf8}{trailer}',\n",
    "    }\n",
    "\n",
    "mastermeta = {'author': 'Geoffrey Khan, Cody Kingham, and Hannes Vlaardingerbroek'}\n",
    "\n",
    "meta = {'':mastermeta,\n",
    "        'oslots':{'edgeValues':False, 'valueType':'int'},\n",
    "        'otype':{'valueType':'str'},\n",
    "        'paragraph':{'valueType':'str'},\n",
    "        'line':{'valueType':'str'},\n",
    "        'utf8':{'valueType':'str'},\n",
    "        'text_id':{'valueType':'str'},\n",
    "        'title':{'valueType':'str'},\n",
    "        'dialect':{'valueType':'str'},\n",
    "        'filename':{'valueType':'str'},\n",
    "        'language':{'valueType':'str'},\n",
    "        'trailer':{'valueType':'str'},\n",
    "        'informant':{'valueType':'str'},\n",
    "        'place':{'valueType':'str'},\n",
    "        'otext':otext\n",
    "       }\n",
    "\n",
    "TFs = Fabric(locations=['tf/'])\n",
    "\n",
    "TFs.save(nodeFeatures=node_features, edgeFeatures=edge_features, metaData=meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load New TF Resource for Enhancements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.8.5\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "14 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations='tf/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.29s T otype                from tf\n",
      "   |     4.66s T oslots               from tf\n",
      "   |     0.00s No structure info in otext, the structure part of the T-API cannot be used\n",
      "   |     1.12s T utf8                 from tf\n",
      "   |     0.00s T title                from tf\n",
      "   |     0.84s T trailer              from tf\n",
      "   |     0.01s T line                 from tf\n",
      "   |     0.00s T dialect              from tf\n",
      "   |      |     0.21s C __levels__           from otype, oslots, otext\n",
      "   |      |     9.28s C __order__            from otype, oslots, __levels__\n",
      "   |      |     0.37s C __rank__             from otype, __order__\n",
      "   |      |     8.45s C __levUp__            from otype, oslots, __rank__\n",
      "   |      |     2.71s C __levDown__          from otype, __levUp__, __rank__\n",
      "   |      |     2.61s C __boundary__         from otype, oslots, __rank__\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   |      |     0.01s c __sections__         WARNING:    1 x section line without containing text\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |      |     0.01s C __sections__         from otype, oslots, otext, __levUp__, __levels__, dialect, title, line\n",
      "   |     0.00s T text_id              from tf\n",
      "   |     0.01s T language             from tf\n",
      "    31s All features loaded/computed - for details use loadLog()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N = TF.load('''\n",
    "\n",
    "text_id paragraph line utf8 \n",
    "otype title dialect language trailer\n",
    "\n",
    "''')\n",
    "\n",
    "N.makeAvailableIn(globals())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhancements and Extensions\n",
    "\n",
    "Some features are easier to make once the TF resource is built. The following features will be constructed:\n",
    "\n",
    "* `utf8` will be extended to word objects to aid in word searches.\n",
    "* `trans_full` will be added to char, morpheme, and word objects.\n",
    "* `trans_lite` will be added to char, morpheme, and word objects. Same as `trans_full` but without accents over vowels. \n",
    "* `trans_trailer` is added to char, morpheme, and word objects. The trailer is a simple space separation for end of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two tables are presented below\n",
    "# they are largely identical, but edits\n",
    "# are made as necessary on a char by char basis.\n",
    "# The tables are used by the function `trans` to \n",
    "# to transcribe the utf8 texts\n",
    "\n",
    "trans_full = {\n",
    "    # non-latin vowels\n",
    "    '\\u0131': '1',  # 0x0131 ı dotless i\n",
    "    '\\u0251': '@',  # 0x0251 ɑ alpha\n",
    "    '\\u0259': '3',  # 0x0259 ə schwa\n",
    "    '\\u025B': '$',  # 0x025B ɛ open e\n",
    "    # vowel accents\n",
    "    '\\u0300': '`',  # 0x0300 à grave\n",
    "    '\\u0301': \"'\",  # 0x0301 á acute\n",
    "    '\\u0304': '_',  # 0x0304 ā macron\n",
    "    '\\u0306': '%',  # 0x0306 ă breve\n",
    "    '\\u0308': '\"',  # 0x0308 ä diaeresis\n",
    "    '\\u0303': '~',  # 0x0303 ã tilde\n",
    "    '\\u02C8': '', # 0x2c8 ˈ small vertical line\n",
    "    # non-latin consonants\n",
    "    '\\u00F0': '6',  # 0x00F0 ð eth\n",
    "    '\\u025F': '&',  # 0x025F ɟ small dotless j with stroke\n",
    "    '\\u0248': '!',  # 0x0248 Ɉ capital J with stroke\n",
    "    '\\u03B8': '8',  # 0x03B8 θ greek theta\n",
    "    '\\u02B8': '7',  # 0x02B8 ʸ small superscript y\n",
    "    '\\u02BE': '}',  # 0x02BE ʾ right half ring (alaph)\n",
    "    '\\u02BF': '{',  # 0x02BF ʿ left half ring (ayin)\n",
    "    # consonant diacritics\n",
    "    '\\u030C': '<',  # 0x030C x̌ caron\n",
    "    '\\u0302': '^',  # 0x0302 x̂ circumflex\n",
    "    '\\u0307': ';',  # 0x0307 ẋ dot above\n",
    "    '\\u0323': '.',  # 0x0323 x̣ dot below\n",
    "    '\\u032D': '>',  # 0x032D x̭ circumflex below\n",
    "}\n",
    "\n",
    "trans_lite = {\n",
    "    # non-latin vowels\n",
    "    '\\u0131': '1',  # 0x0131 ı dotless i\n",
    "    '\\u0251': 'a',  # 0x0251 ɑ alpha\n",
    "    '\\u0259': '3',  # 0x0259 ə schwa\n",
    "    '\\u025B': 'e',  # 0x025B ɛ open e\n",
    "    # vowel accents\n",
    "    '\\u0300': '',  # 0x0300 à grave\n",
    "    '\\u0301': \"\",  # 0x0301 á acute\n",
    "    '\\u0304': '',  # 0x0304 ā macron\n",
    "    '\\u0306': '',  # 0x0306 ă breve\n",
    "    '\\u0308': '',  # 0x0308 ä diaeresis\n",
    "    '\\u0303': '',  # 0x0303 ã tilde\n",
    "    '\\u02C8': '', # 0x2c8 ˈ small vertical line\n",
    "    # non-latin consonants\n",
    "    '\\u00F0': '6',  # 0x00F0 ð eth\n",
    "    '\\u025F': '&',  # 0x025F ɟ small dotless j with stroke\n",
    "    '\\u0248': '!',  # 0x0248 Ɉ capital J with stroke\n",
    "    '\\u03B8': '8',  # 0x03B8 θ greek theta\n",
    "    '\\u02B8': '7',  # 0x02B8 ʸ small superscript y\n",
    "    '\\u02BE': '}',  # 0x02BE ʾ right half ring (alaph)\n",
    "    '\\u02BF': '{',  # 0x02BF ʿ left half ring (ayin)\n",
    "    # consonant diacritics\n",
    "    '\\u030C': '<',  # 0x030C x̌ caron\n",
    "    '\\u0302': '^',  # 0x0302 x̂ circumflex\n",
    "    '\\u0307': ';',  # 0x0307 ẋ dot above\n",
    "    '\\u0323': '.',  # 0x0323 x̣ dot below\n",
    "    '\\u032D': '>',  # 0x032D x̭ circumflex below\n",
    "}\n",
    "\n",
    "def trans(s, table):\n",
    "    '''\n",
    "    Transcribes a text.\n",
    "    '''\n",
    "    s = unicodedata.normalize('NFD', s)\n",
    "    s = s.strip('\\n |,.!?:;')\n",
    "    return ''.join([table.get(c, c) for c in s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remake Existing Char Features and Extend them with New ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_features = collections.defaultdict(lambda: collections.defaultdict())\n",
    "\n",
    "# first re-create the features\n",
    "for char in F.otype.s('char'):\n",
    "    # remake utf8\n",
    "    extend_features['utf8'][char] = F.utf8.v(char)\n",
    "    # remake trailer\n",
    "    extend_features['trailer'][char] = F.trailer.v(char)\n",
    "    \n",
    "    # apply extra features\n",
    "    extend_features['trans_full'][char] = trans(F.utf8.v(char), trans_full)\n",
    "    extend_features['trans_lite'][char] = trans(F.utf8.v(char), trans_lite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend `utf8` Feature to Word and Morpheme Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add words and morphemes; compose without trailer\n",
    "\n",
    "for otype in ('word', 'morpheme'):\n",
    "    \n",
    "    for obj in F.otype.s(otype):\n",
    "    \n",
    "        # compose text features from characters\n",
    "        utf8 = '' # full utf8 representation\n",
    "        transF = '' # trans full\n",
    "        transL = '' # trans lite\n",
    "        \n",
    "        for char in L.d(obj, 'char'):\n",
    "            \n",
    "            utf8 += F.utf8.v(char)\n",
    "            transF += trans(F.utf8.v(char), trans_full)\n",
    "            transL += trans(F.utf8.v(char), trans_lite)\n",
    "            \n",
    "            # only add trailing morpheme hyphens to words\n",
    "            if otype == 'word' and F.trailer.v(char) == '-':\n",
    "                utf8 += F.trailer.v(char)\n",
    "                \n",
    "            # add trailer feature\n",
    "            if char == L.d(obj, 'char')[-1]: # is last char\n",
    "                extend_features['trailer'][obj] = F.trailer.v(char)\n",
    "    \n",
    "        # add all features to objects\n",
    "        pretty_txt = unicodedata.normalize('NFC', utf8) # make pretty unicode \n",
    "        extend_features['utf8'][obj] = pretty_txt\n",
    "        extend_features['trans_full'][obj] = transF\n",
    "        extend_features['trans_lite'][obj] = transL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Extended Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.8.5\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "14 features found and 0 ignored\n",
      "  0.00s Exporting 4 node and 0 edge and 1 config features to tf/:\n",
      "   |     0.96s T trailer              to tf\n",
      "   |     0.96s T trans_full           to tf\n",
      "   |     0.96s T trans_lite           to tf\n",
      "   |     1.00s T utf8                 to tf\n",
      "   |     0.00s M otext                to tf\n",
      "  3.88s Exported 4 node features and 0 edge features and 1 config features to tf/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a new otext to include new text formats\n",
    "otext = {\n",
    "    'sectionTypes': 'dialect,text,line',\n",
    "    'sectionFeatures': 'dialect,title,line',\n",
    "    'fmt:text-orig-full': '{utf8}{trailer}',\n",
    "    'fmt:text-trans-full': '{trans_full}{trailer}',\n",
    "    'fmt:text-trans-plain': '{trans_lite}{trailer}'\n",
    "    }\n",
    "\n",
    "meta = {'':mastermeta,\n",
    "        'utf8': {'valueType':'str'},\n",
    "        'trans_full':{'valueType':'str',\n",
    "                      'description':'A full transcription on char, morpheme, and word objects.'},\n",
    "        'trans_lite':{'valueType':'str',\n",
    "                      'description':'A lite transcription on char, morpheme, and word objects.'},\n",
    "        'trailer':{'valueType':'str'},\n",
    "        'otext': otext\n",
    "       }\n",
    "\n",
    "TFs = Fabric(locations=['tf/'])\n",
    "\n",
    "TFs.save(nodeFeatures=extend_features, metaData=meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Load Enhanced TF Resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.8.4\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "14 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations='tf/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.00s No structure info in otext, the structure part of the T-API cannot be used\n",
      "   |     1.79s T utf8                 from tf\n",
      "   |     1.19s T trailer              from tf\n",
      "  4.52s All features loaded/computed - for details use loadLog()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N = TF.load('''\n",
    "\n",
    "text_id paragraph line utf8 \n",
    "otype title dialect language trailer\n",
    "\n",
    "''')\n",
    "\n",
    "N.makeAvailableIn(globals())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Source of Line Warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552511 mə́ra wírra šəkwánta qamɛ́θa šqilála ða-ḥábba ʾu-plìṭla.ˈ wírra t-tə́rte šqilála ða-ḥábba-w plìṭla.ˈ wírra t-ṭə́ḷḷəθ ða-ḥábba-w plìṭla.ˈ mə́ra ha-t-xásli ʾan-xə̀ṭṭe,ˈ ʾan-šəkwáne ṱ-áwɛ ðà-ða wára.ˈ líθ dúka t-tə̀rte.ˈ har-ðà-ða wára.ˈ mə́re dū̀s,ˈ ʾáy čú-ga la-xàsla.ˈ ʾìθwaˈ xá familyˈ bàbaˈ ʾu-brònaˈ ʾu-báxtət bròna.ˈ ʾo-bàbaˈ píšɛwa sàwa.ˈ sáwɛwa gu-bɛ̀θa.ˈ kálθe díye sqìdla mə́nne.ˈ\n",
      "\n",
      "(657410, 657411, 657412, 657413, 657414, 657415, 657416, 657417, 657418, 657419, 657420, 657421, 657422, 657423, 657424, 657425, 657426, 657427, 657428, 657429, 657430, 657431, 657432, 657433, 657434, 657435, 657436, 657437, 657438, 657439, 657440, 657441, 657442, 657443, 657444, 657445, 657446, 657447, 657448, 657449, 657450, 657451, 657452, 657453, 657454, 657455, 657456, 657457, 657458)\n"
     ]
    }
   ],
   "source": [
    "for line in F.otype.s('line'):\n",
    "    \n",
    "    if not L.u(line, 'text'):\n",
    "        \n",
    "        print(line, T.text(line))\n",
    "        print()\n",
    "        print(L.d(line, 'word'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x2c8'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(ord('ˈ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657361 Barwar ('Barwar', 'THE STORY WITH NO END', '3') mə́ra \n",
      "657362 Barwar ('Barwar', 'THE STORY WITH NO END', '3') ʾíθwa \n",
      "657363 Barwar ('Barwar', 'THE STORY WITH NO END', '3') xa-málka \n",
      "657364 Barwar ('Barwar', 'THE STORY WITH NO END', '3') ẓalə́m-wewa \n",
      "657365 Barwar ('Barwar', 'THE STORY WITH NO END', '3') maxwàθux.ˈ \n",
      "657366 Barwar ('Barwar', 'THE STORY WITH NO END', '3') ʾíθwale \n",
      "657367 Barwar ('Barwar', 'THE STORY WITH NO END', '3') xa-muqaṭăʿa \n",
      "657368 Barwar ('Barwar', 'THE STORY WITH NO END', '3') rába \n",
      "657369 Barwar ('Barwar', 'THE STORY WITH NO END', '3') gòṛa.ˈ \n",
      "657370 Barwar ('Barwar', 'THE STORY WITH NO END', '3') mjŭmɛ́le \n",
      "657371 Barwar ('Barwar', 'THE STORY WITH NO END', '3') xə́ṭṭe \n",
      "657372 Barwar ('Barwar', 'THE STORY WITH NO END', '3') t-kúlla \n",
      "657373 Barwar ('Barwar', 'THE STORY WITH NO END', '3') d-ɛ-mànṭăqa.ˈ \n",
      "657374 Barwar ('Barwar', 'THE STORY WITH NO END', '3') drɛ́le \n",
      "657375 Barwar ('Barwar', 'THE STORY WITH NO END', '3') gu-sèylo.ˈ \n",
      "657376 Barwar ('Barwar', 'THE STORY WITH NO END', '3') mə́ra \n",
      "657377 Barwar ('Barwar', 'THE STORY WITH NO END', '3') qəm-daréla \n",
      "657378 Barwar ('Barwar', 'THE STORY WITH NO END', '3') kúlla \n",
      "657379 Barwar ('Barwar', 'THE STORY WITH NO END', '3') gu-d-àyˈ \n",
      "657380 Barwar ('Barwar', 'THE STORY WITH NO END', '3') ʾu-qəm-šăyéla \n",
      "657381 Barwar ('Barwar', 'THE STORY WITH NO END', '3') kúlla \n",
      "657382 Barwar ('Barwar', 'THE STORY WITH NO END', '3') gudána \n",
      "657383 Barwar ('Barwar', 'THE STORY WITH NO END', '3') dìyaˈ \n",
      "657384 Barwar ('Barwar', 'THE STORY WITH NO END', '3') b-čimàntoˈ \n",
      "657385 Barwar ('Barwar', 'THE STORY WITH NO END', '3') ʾu-t-lá \n",
      "657386 Barwar ('Barwar', 'THE STORY WITH NO END', '3') háwe \n",
      "657387 Barwar ('Barwar', 'THE STORY WITH NO END', '3') tằra-ži \n",
      "657388 Barwar ('Barwar', 'THE STORY WITH NO END', '3') bíya \n",
      "657389 Barwar ('Barwar', 'THE STORY WITH NO END', '3') díya.ˈ\n"
     ]
    }
   ],
   "source": [
    "for w in L.d(552509, 'word'):\n",
    "    text = L.u(w, 'text')[0]\n",
    "    print(w, F.dialect.v(text), T.sectionFromNode(w), T.text(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this line extends over two texts. This is due to an error in the source text, where there is a missing \"(1)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Text Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sectioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Barwar', 'The Monk And The Angel', '1')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.sectionFromNode(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UTF8 Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_chars\n",
      "\tʾ\n",
      "\tì\n",
      "\tθ\n",
      "\tw\n",
      "\ta\n",
      "\tx\n",
      "\ta\n",
      "\tr\n",
      "\tà\n",
      "\tb\n",
      "\tb\n",
      "\tə\n",
      "\tn\n",
      "\tt\n",
      "\tí\n",
      "\tw\n",
      "\tɛ\n",
      "\tw\n",
      "\ta\n",
      "\tg\n",
      "\n",
      "first_morphs\n",
      "\tʾìθwa\n",
      "\txa\n",
      "\tràbbən\n",
      "\ttíwɛwa\n",
      "\tgu\n",
      "\txa\n",
      "\tgəppìθa\n",
      "\tθéle\n",
      "\txa\n",
      "\tnáša\n",
      "\tswarìya\n",
      "\trakáwa\n",
      "\tṣléle\n",
      "\trəš\n",
      "\txa\n",
      "\n",
      "first_words\n",
      "\tʾìθwa\n",
      "\txa-ràbbən\n",
      "\ttíwɛwa\n",
      "\tgu-xa-gəppìθa\n",
      "\tθéle\n",
      "\txa-náša\n",
      "\tswarìya\n",
      "\trakáwa\n",
      "\tṣléle\n",
      "\trəš-xa-ʾɛ̀na\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utf8s = {'first_chars' : list(F.otype.s('char'))[:20],\n",
    "         'first_morphs': list(F.otype.s('morpheme'))[:15],\n",
    "         'first_words' : list(F.otype.s('word'))[:10],}\n",
    "\n",
    "for otype, objs in utf8s.items():\n",
    "    print(otype)\n",
    "    for obj in objs:\n",
    "        print(f'\\t{F.utf8.v(obj)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trailer\n",
    "\n",
    "Object + trailer is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_chars\n",
      "\tʾ\n",
      "\tì\n",
      "\tθ\n",
      "\tw\n",
      "\taˈ \n",
      "\tx\n",
      "\ta-\n",
      "\tr\n",
      "\tà\n",
      "\tb\n",
      "\tb\n",
      "\tə\n",
      "\tn,ˈ \n",
      "\tt\n",
      "\tí\n",
      "\tw\n",
      "\tɛ\n",
      "\tw\n",
      "\ta \n",
      "\tg\n",
      "\n",
      "first_morphs\n",
      "\tʾìθwaˈ \n",
      "\txa-\n",
      "\tràbbən,ˈ \n",
      "\ttíwɛwa \n",
      "\tgu-\n",
      "\txa-\n",
      "\tgəppìθa.ˈ \n",
      "\tθéle \n",
      "\txa-\n",
      "\tnáša \n",
      "\tswarìya,ˈ \n",
      "\trakáwa.ˈ \n",
      "\tṣléle \n",
      "\trəš-\n",
      "\txa-\n",
      "\n",
      "first_words\n",
      "\tʾìθwaˈ \n",
      "\txa-ràbbən,ˈ \n",
      "\ttíwɛwa \n",
      "\tgu-xa-gəppìθa.ˈ \n",
      "\tθéle \n",
      "\txa-náša \n",
      "\tswarìya,ˈ \n",
      "\trakáwa.ˈ \n",
      "\tṣléle \n",
      "\trəš-xa-ʾɛ̀na.ˈ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for otype, objs in utf8s.items():\n",
    "    print(otype)\n",
    "    for obj in objs:\n",
    "        otext = F.utf8.v(obj)\n",
    "        print(f'\\t{otext}{F.trailer.v(obj)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "### Object Types and Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialect                      2\n",
      "text                       126\n",
      "paragraph                  465\n",
      "line                      2543\n",
      "sentence                 16784\n",
      "subsentence              24541\n",
      "prosa                    35967\n",
      "word                     93762\n",
      "morpheme                120134\n",
      "char                    551014\n"
     ]
    }
   ],
   "source": [
    "for otype in F.otype.all:\n",
    "    print('{:20}{:>10}'.format(otype, len(list(F.otype.s(otype)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts and their word counts: \n",
      "\n",
      "551017 A15 Barwar The Monk And The Angel\n",
      "\t680 words, 950 morphemes\n",
      "551018 A16 Urmi_C THE MONK WHO WANTED TO KNOW WHEN HE WOULD DIE\n",
      "\t368 words, 487 morphemes\n",
      "551019 A17 Barwar THE WISE YOUNG MAN\n",
      "\t1091 words, 1482 morphemes\n",
      "551020 A45 Barwar THE FOX AND THE STORK\n",
      "\t70 words, 102 morphemes\n",
      "551021 A28 Barwar THE TALE OF RUSTAM (1)\n",
      "\t1008 words, 1316 morphemes\n",
      "551022 A49 Barwar THE CROW AND THE CHEESE\n",
      "\t51 words, 71 morphemes\n",
      "551023 A24 Barwar THE TALE OF PARIZADA, WARDA AND NARGIS\n",
      "\t2016 words, 2698 morphemes\n",
      "551024 A42 Barwar THE FOX AND THE LION\n",
      "\t95 words, 124 morphemes\n",
      "551025 A43 Barwar SOUR GRAPES\n",
      "\t62 words, 82 morphemes\n",
      "551026 A44 Barwar THE CAT AND THE MICE\n",
      "\t99 words, 138 morphemes\n",
      "551027 A25 Barwar THE TALE OF FARXO AND SƏTTIYA\n",
      "\t2490 words, 3303 morphemes\n",
      "551028 A48 Barwar THE MAN WHO CRIED WOLF\n",
      "\t199 words, 250 morphemes\n",
      "551029 A29 Barwar THE TALE OF RUSTAM (2)\n",
      "\t1645 words, 2254 morphemes\n",
      "551030 A9 Barwar THE SCORPION AND THE SNAKE\n",
      "\t216 words, 298 morphemes\n",
      "551031 A10 Barwar I AM WORTH THE SAME AS A BLIND WOLF\n",
      "\t528 words, 713 morphemes\n",
      "551032 A11 Barwar DƏMDƏMA\n",
      "\t620 words, 849 morphemes\n",
      "551033 A12 Barwar THE KING WITH FORTY SONS\n",
      "\t2539 words, 3366 morphemes\n",
      "551034 A13 Barwar A TALE OF TWO KINGS\n",
      "\t513 words, 703 morphemes\n",
      "551035 A46 Barwar THE LION KING\n",
      "\t114 words, 150 morphemes\n",
      "551036 A47 Barwar MAN IS TREACHEROUS\n",
      "\t227 words, 313 morphemes\n",
      "551037 A37 Barwar THE TALE OF NASIMO\n",
      "\t389 words, 500 morphemes\n",
      "551038 A38 Barwar ŠOŠƏT XERE\n",
      "\t349 words, 439 morphemes\n",
      "551039 A39 Barwar THE BROTHER OF GIANTS\n",
      "\t474 words, 659 morphemes\n",
      "551040 A40 Barwar THE WISE DAUGHTER OF THE KING\n",
      "\t388 words, 535 morphemes\n",
      "551041 A18 Barwar BABY LELIΘA\n",
      "\t845 words, 1148 morphemes\n",
      "551042 A1 Barwar The Wise Snake\n",
      "\t779 words, 1020 morphemes\n",
      "551043 A2 Barwar The Priest and the Mullah\n",
      "\t317 words, 435 morphemes\n",
      "551044 A3 Barwar The Selfish Neighbour\n",
      "\t146 words, 210 morphemes\n",
      "551045 A4 Barwar A tale of a prince and a princess\n",
      "\t1763 words, 2437 morphemes\n",
      "551046 A5 Barwar The Cooking Pot\n",
      "\t254 words, 327 morphemes\n",
      "551047 A6 Barwar A Hundred Gold Coins\n",
      "\t343 words, 483 morphemes\n",
      "551048 A7 Barwar A Man Called Čuxo\n",
      "\t789 words, 1041 morphemes\n",
      "551049 A34 Barwar THE GIRL AND THE SEVEN BROTHERS\n",
      "\t744 words, 1030 morphemes\n",
      "551050 A14 Barwar TALES FROM THE 1001 NIGHTS\n",
      "\t3018 words, 4195 morphemes\n",
      "551051 A35 Barwar NANNO AND JƏNDO\n",
      "\t641 words, 865 morphemes\n",
      "551052 A36 Barwar THE STORY WITH NO END\n",
      "\t130 words, 195 morphemes\n",
      "551053 A41 Barwar MEASURE FOR MEASURE\n",
      "\t132 words, 174 morphemes\n",
      "551054 A8 Barwar Gozali and Nozali\n",
      "\t3828 words, 5424 morphemes\n",
      "551055 A19 Barwar THE LELIΘA FROM Č̭ĀL\n",
      "\t252 words, 321 morphemes\n",
      "551056 A20 Barwar THE BEAR AND THE FOX\n",
      "\t363 words, 506 morphemes\n",
      "551057 A21 Barwar THE DAUGHTER OF THE KING\n",
      "\t1264 words, 1716 morphemes\n",
      "551058 A22 Barwar THE SALE OF AN OX\n",
      "\t1294 words, 1711 morphemes\n",
      "551059 A23 Barwar THE MAN WHO WANTED TO WORK\n",
      "\t1066 words, 1461 morphemes\n",
      "551060 A26 Barwar THE TALE OF MĂMO AND ZINE\n",
      "\t2633 words, 3510 morphemes\n",
      "551061 A30 Barwar THE CRAFTY HIRELING\n",
      "\t1362 words, 1818 morphemes\n",
      "551062 A31 Barwar THE GIANT’S CAVE\n",
      "\t238 words, 336 morphemes\n",
      "551063 A32 Barwar THE FOX AND THE MILLER\n",
      "\t841 words, 1101 morphemes\n",
      "551064 A33 Barwar THE LION WITH A SWOLLEN LEG\n",
      "\t378 words, 494 morphemes\n",
      "551065 A50 Barwar THE SISISAMBƏR PLANT\n",
      "\t289 words, 385 morphemes\n",
      "551066 A51 Barwar QAṬINA RESCUES HIS NEPHEW FROM LELIΘA\n",
      "\t358 words, 492 morphemes\n",
      "551067 A52 Barwar THE BATTLE WITH YUWANƏS THE ARMENIAN\n",
      "\t607 words, 780 morphemes\n",
      "551068 A27 Barwar THE TALE OF MƏRZA PĂMƏT\n",
      "\t1090 words, 1473 morphemes\n",
      "551069 A 1 Urmi_C The Bald Man and the King\n",
      "\t2652 words, 3218 morphemes\n",
      "551070 A2 Urmi_C Women are Stronger than Men\n",
      "\t935 words, 1142 morphemes\n",
      "551071 A3 Urmi_C Axiqar\n",
      "\t2656 words, 3300 morphemes\n",
      "551072 A4 Urmi_C Is there a Man with No Worries?\n",
      "\t796 words, 992 morphemes\n",
      "551073 A5 Urmi_C Women do Things Best\n",
      "\t842 words, 1071 morphemes\n",
      "551074 A6 Urmi_C The Dead Rise and Return\n",
      "\t643 words, 790 morphemes\n",
      "551075 A7 Urmi_C A Pound of Flesh\n",
      "\t752 words, 915 morphemes\n",
      "551076 A8 Urmi_C The Loan of a Cooking Pot\n",
      "\t156 words, 190 morphemes\n",
      "551077 A9 Urmi_C Much Ado About Nothing\n",
      "\t334 words, 392 morphemes\n",
      "551078 A10 Urmi_C A Visit from Harun ar-Rashid\n",
      "\t489 words, 591 morphemes\n",
      "551079 A11 Urmi_C The Cat’s Dinner\n",
      "\t115 words, 129 morphemes\n",
      "551080 A12 Urmi_C Ice for Dinner\n",
      "\t91 words, 108 morphemes\n",
      "551081 A13 Urmi_C Am I dead?\n",
      "\t90 words, 118 morphemes\n",
      "551082 A14 Urmi_C A Thousand Dinars\n",
      "\t472 words, 589 morphemes\n",
      "551083 A15 Urmi_C Kindness to a Donkey\n",
      "\t64 words, 79 morphemes\n",
      "551084 A16 Urmi_C The Stupid Carpenter\n",
      "\t111 words, 142 morphemes\n",
      "551085 A17 Urmi_C A Close Shave\n",
      "\t71 words, 91 morphemes\n",
      "551086 A18 Urmi_C A Sweater to Pay Off a Debt\n",
      "\t77 words, 97 morphemes\n",
      "551087 A19 Urmi_C No Bread Today\n",
      "\t188 words, 239 morphemes\n",
      "551088 A20 Urmi_C An Orphan Duckling\n",
      "\t63 words, 72 morphemes\n",
      "551089 A21 Urmi_C Mistaken Identity\n",
      "\t110 words, 139 morphemes\n",
      "551090 A22 Urmi_C Trickster\n",
      "\t157 words, 193 morphemes\n",
      "551091 A23 Urmi_C Problems Lighting a Fire\n",
      "\t132 words, 156 morphemes\n",
      "551092 A24 Urmi_C The Angel of Death\n",
      "\t82 words, 103 morphemes\n",
      "551093 A25 Urmi_C Stomach Trouble\n",
      "\t41 words, 46 morphemes\n",
      "551094 A26 Urmi_C A Lost Donkey\n",
      "\t65 words, 84 morphemes\n",
      "551095 A27 Urmi_C A Lost Ring\n",
      "\t38 words, 47 morphemes\n",
      "551096 A28 Urmi_C The Purchase of a Donkey\n",
      "\t184 words, 221 morphemes\n",
      "551097 A29 Urmi_C Lost Money\n",
      "\t51 words, 62 morphemes\n",
      "551098 A30 Urmi_C The Wife’s Condition\n",
      "\t210 words, 254 morphemes\n",
      "551099 A31 Urmi_C A Donkey Knows Best\n",
      "\t95 words, 126 morphemes\n",
      "551100 A32 Urmi_C When Shall I Die?\n",
      "\t148 words, 189 morphemes\n",
      "551101 A33 Urmi_C I Have Died\n",
      "\t102 words, 129 morphemes\n",
      "551102 A34 Urmi_C The Fisherman and the Princess\n",
      "\t702 words, 807 morphemes\n",
      "551103 A35.1 Urmi_C The Wife who Learns How to Work\n",
      "\t690 words, 812 morphemes\n",
      "551104 A35.2 Urmi_C The Wife who Learns How to Work\n",
      "\t305 words, 386 morphemes\n",
      "551105 A36 Urmi_C A Cure for a Husband’s Madness\n",
      "\t1282 words, 1512 morphemes\n",
      "551106 A37 Urmi_C The Bald Child and the Monsters\n",
      "\t1042 words, 1259 morphemes\n",
      "551107 A38 Urmi_C The Wise Young Daughter\n",
      "\t1005 words, 1228 morphemes\n",
      "551108 A39 Urmi_C The Adventures of Ashur\n",
      "\t2719 words, 3294 morphemes\n",
      "551109 A40 Urmi_C A Dragon in the Well\n",
      "\t528 words, 666 morphemes\n",
      "551110 A41 Urmi_C A Painting of the King Of Iran\n",
      "\t763 words, 947 morphemes\n",
      "551111 A42 Urmi_C The Adventures of Two Brothers\n",
      "\t2131 words, 2541 morphemes\n",
      "551112 A43 Urmi_C The Adventures of a Princess\n",
      "\t1887 words, 2209 morphemes\n",
      "551113 A44 Urmi_C Two Wicked Daughters-in-law\n",
      "\t689 words, 788 morphemes\n",
      "551114 A45 Urmi_C A Dutiful Son\n",
      "\t1065 words, 1204 morphemes\n",
      "551115 A46 Urmi_C The Little Prince and the Snake\n",
      "\t243 words, 284 morphemes\n",
      "551116 A47 Urmi_C The Snake’s Dilemma\n",
      "\t1024 words, 1345 morphemes\n",
      "551117 A48 Urmi_C The Wise Brother\n",
      "\t1619 words, 1991 morphemes\n",
      "551118 A49 Urmi_C The Man who Wanted to Complain to God\n",
      "\t513 words, 614 morphemes\n",
      "551119 A50 Urmi_C The Giant One-Eyed Demon\n",
      "\t390 words, 495 morphemes\n",
      "551120 A51 Urmi_C The Cow and The Poor Girl\n",
      "\t578 words, 671 morphemes\n",
      "551121 A52 Urmi_C A Frog Wants a Husband\n",
      "\t460 words, 554 morphemes\n",
      "551122 A53 Urmi_C The Bird and the Fox\n",
      "\t233 words, 259 morphemes\n",
      "551123 A54 Urmi_C The Old Man and the Fish\n",
      "\t543 words, 630 morphemes\n",
      "551124 A55 Urmi_C Two Birds Fall in Love\n",
      "\t412 words, 485 morphemes\n",
      "551125 A56 Urmi_C Star-Crossed Lovers\n",
      "\t294 words, 353 morphemes\n",
      "551126 B1 Urmi_C The Assyrians of Urmi\n",
      "\t2268 words, 2768 morphemes\n",
      "551127 B2 Urmi_C Village Life\n",
      "\t1064 words, 1372 morphemes\n",
      "551128 B3 Urmi_C Agriculture and Village Life\n",
      "\t2028 words, 2487 morphemes\n",
      "551129 B4 Urmi_C Hunting\n",
      "\t938 words, 1139 morphemes\n",
      "551130 B5 Urmi_C Weddings and Festivals\n",
      "\t727 words, 879 morphemes\n",
      "551131 B6 Urmi_C Events in 1946 on the Urmi Plain\n",
      "\t509 words, 639 morphemes\n",
      "551132 B7 Urmi_C Village Life\n",
      "\t1263 words, 1614 morphemes\n",
      "551133 B8 Urmi_C Weddings\n",
      "\t425 words, 534 morphemes\n",
      "551134 B9 Urmi_C Games\n",
      "\t793 words, 1010 morphemes\n",
      "551135 B10 Urmi_C Village Life\n",
      "\t1796 words, 2226 morphemes\n",
      "551136 B11 Urmi_C St. Zayya’s Cake Dough\n",
      "\t554 words, 720 morphemes\n",
      "551137 B12 Urmi_C Nipuxta\n",
      "\t366 words, 507 morphemes\n",
      "551138 B13 Urmi_C Vineyards\n",
      "\t156 words, 199 morphemes\n",
      "551139 B14 Urmi_C Village Life\n",
      "\t604 words, 812 morphemes\n",
      "551140 B15 Urmi_C Village Life\n",
      "\t584 words, 684 morphemes\n",
      "551141 B16 Urmi_C The Assyrians of Armenia\n",
      "\t712 words, 786 morphemes\n",
      "551142 B17 Urmi_C Village Life\n",
      "\t2851 words, 3540 morphemes\n"
     ]
    }
   ],
   "source": [
    "print('texts and their word counts: \\n')\n",
    "\n",
    "for text in F.otype.s('text'):\n",
    "    \n",
    "    text_words = L.d(text, 'word')\n",
    "    text_morphemes = L.d(text, 'morpheme')\n",
    "    \n",
    "    print(text, F.text_id.v(text), F.dialect.v(text), F.title.v(text))\n",
    "    print(f'\\t{len(text_words)} words, {len(text_morphemes)} morphemes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = F.otype.s('text')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(L.d(text, 'word'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Monk And The Angel\n",
      "551608 ʾìθwaˈ xa-ràbbən,ˈ tíwɛwa gu-xa-gəppìθa.ˈ θéle xa-náša swarìya,ˈ rakáwa.ˈ ṣléle rəš-xa-ʾɛ̀na.ˈ tìwle,ˈ xílle mə̀ndi,ˈ štéle mìya.ˈ ʾíθwale xákma zùze.ˈ qímle šqilìle.ˈ muttìleˈ rəš-d-ɛ-ʾɛ̀na.ˈ ʾàwwaˈ munšìle zúze díye.ˈ zìlle.ˈ ʾáwwa zílle b-ʾùrxa.ˈ\n",
      "551609 θéle xá rakáwa xèna,ˈ swarìya.ˈ zílle rəš-ʾɛ̀na.ˈ qəm-xazèlaˈ ʾə̀mma dináre.ˈ šqilíle jal-jàldeˈ muttíle gu-jɛ̀beˈ ʾu-zìlle.ˈ ʾo-qamàyaˈ ʾámər ʾòhˈ zúzi munšìli.ˈ qɛ́mən dɛ̀ṛənˈ ʾázən šáqlən zùziˈ m-rəš-ʾɛ̀na.ˈ\n",
      "551610 ha-t-ʾáθe ʾo-náša qamàyaˈ máṭe l-ʾɛ̀naˈ ʾáθe xa-náša sàwa.ˈ máṭe rəš-ʾɛ̀naˈ mattúla kàrteˈ ʾu-tíwle manyòxe.ˈ ʾo-qamáya ṱ-íle zúze mùnšyaˈ θéle ʾə́lle dìye.ˈ ʾàmərˈ mpáləṭla zùzi!,ˈ ʾə́mma dináre ʾána hon-mùnšəlla láxxa.ˈ lázəm yawə̀tla.ˈ yába lán-xəzya zùze,ˈ lá ʾáxxa-w tàmmaˈ ʾu-kízle b-ay-gòta.ˈ là.ˈ\n",
      "551611 mə́re qaṭlə̀nnux.ˈ mə́re qṭùl!ˈ lìtli.ˈ zúze làn-xəzya.ˈ qìmleˈ qəm-qaṭə̀lle.ˈ qəm-qaṭə̀lle.ˈ ràbbənˈ yăðət-mà-yle?ˈ ràbbənˈ ʾáwwa ṱ-i-sàxəð l-ʾálahaˈ ʾu-ṱ-i-mṣàle-uˈ lé-y-ʾaxəl bə̀sra-wˈ ʾáw y-amríle ràbbən.ˈ hóle tíwa gu-xa-gəppìθaˈ ʾarbì-šənne.ˈ\n",
      "551612 qìmɛleˈ mə́re mádam hàtxɛlaˈ ṱ-ázən ṭắyən báθər ḥaqqùθaˈ ʾu-na-ḥaqqùθa.ˈ ʾɛ̀nila ḥaqqúθaˈ ʾu-ʾɛ̀nila na-ḥaqqúθa.ˈ mára ṣə̀lyɛleˈ ta-t-ʾázəl ʾùrxa.ˈ ʾálaha mšúdrəlle malàxa.ˈ\n",
      "551613 mə́re ṣlí qamθə-d-áwwa nàša,ˈ ràbbən,ˈ t-là-xaləṭ.ˈ ṣə́lyɛle qámθe dìye.ˈ mə̀reˈ ha-gàni,ˈ lɛ̀kət zála?ˈ mə̀reˈ hon-zála ṭắya báθər ḥaqqúθa-w na-ḥaqqùθa.ˈ ʾámər ʾap-ʾàna hówən zála ṭắya báθər ḥaqqúθa ʾu-na-ḥaqqùθa.ˈ\n",
      "551614 mə̀re,ˈ maláxa mə́re ṭla-ràbbən,ˈ mə́re ṱ-áwðət b-xàbriˈ kú-məndi ṱ-amrə̀nnux?ˈ ʾámər hè.ˈ mə́re ma-yxàləf.ˈ mə́re ʾána w-áti xonăwàθəx.ˈ zìlela,ˈ zíle, zíle, zíle gu-ðà-maθa.ˈ ʾaṣə̀rtɛla,ˈ b-áyya dána hàtxa,ˈ mə́xyela l-tắrət bɛ́θət xa-nàša.ˈ wìrela gu-bɛ́θa.ˈ\n",
      "551615 šlàma-llɛxu!ˈ b-šɛ́na b-ṭawàθa,ˈ páqðu tìwe!ˈ tíwela tàmaˈ ʾu-xílela ʾixàlaˈ ʾu-píše dmìxe.ˈ dmìxela,ˈ b-lɛ̀le,ˈ maláxa mŭṛə̀šleˈqa-ràbbənˈ mə́re qù!ˈ qù!ˈ mə́re há də-šúqlən dàmxəx.ˈ lɛ́t-mira ṱ-óðən b-xàbrux?ˈ qu-šqúlla ʾáyya skìnta.ˈ si-prúmle ʾáwwa yála zòraˈ ṱ-íle gu-dudìya.ˈ\n",
      "551616 ʾaw-mə̀reˈ dáx pɛrmə́nne ʾàwwa?ˈ mút ḥaqqúθa na-ḥaqqùθɛla?ˈ mə́re nə́mu lɛ́t-mira ṱ-óðən b-xàbrux?ˈ ʾàyyɛla.ˈ bắyət bằyət.ˈ la-bắyət si-prúmle yàla.ˈ bába-w yə́mmət yàlaˈ xamši-šə́nne ʾíθwala ʾùmraˈ líθwala bnòne.ˈ ʾáwwa yála yíwəlle ʾálaha ʾə́lla díya ʾəštà yárxe.ˈ\n",
      "551617 ʾu-ʾáp-ʾawwa qəm-parmìle.ˈ ʾu-zìlla.ˈ b-lɛ̀le,ˈ zìlla,ˈ síqla xa-máθa xèta.ˈ mə́re ʾáyya mút ḥaqqúθa na-ḥaqqùθɛla,ˈ ya-ʾaxòni?ˈ hátxa măləpə́tli ḥaqqúθa ʾu-na-ḥaqqùθa.ˈ zílela gu-ða-máθa xèta.ˈ màra,ˈ ʾímət sìqlaˈ gu-d-ɛ̀-maθa,ˈ wírra gu-xa-bɛ̀θa.ˈ\n"
     ]
    }
   ],
   "source": [
    "print(F.title.v(text))\n",
    "\n",
    "for sent in F.otype.s('line')[:10]:\n",
    "    print(sent, T.text(sent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631644 šlàma-llɛxu\n",
      "631645 b-šɛ́na\n",
      "631646 b-ṭawàθa\n",
      "631647 páqðu\n",
      "631648 tìwe\n",
      "631649 tíwela\n",
      "631650 tàma\n",
      "631651 ʾu-xílela\n",
      "631652 ʾixàla\n",
      "631653 ʾu-píše\n",
      "631654 dmìxe\n",
      "631655 dmìxela\n",
      "631656 b-lɛ̀le\n",
      "631657 maláxa\n",
      "631658 mŭṛə̀šle\n",
      "631659 qa-ràbbən\n",
      "631660 mə́re\n",
      "631661 qù\n",
      "631662 qù\n",
      "631663 mə́re\n",
      "631664 há\n",
      "631665 də-šúqlən\n",
      "631666 dàmxəx\n",
      "631667 lɛ́t-mira\n",
      "631668 ṱ-óðən\n",
      "631669 b-xàbrux\n",
      "631670 qu-šqúlla\n",
      "631671 ʾáyya\n",
      "631672 skìnta\n",
      "631673 si-prúmle\n",
      "631674 ʾáwwa\n",
      "631675 yála\n",
      "631676 zòra\n",
      "631677 ṱ-íle\n",
      "631678 gu-dudìya\n"
     ]
    }
   ],
   "source": [
    "for w in L.d(551615, 'word'):\n",
    "    print(w, F.utf8.v(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Query Capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = F.utf8.v(631728)\n",
    "\n",
    "find = list(S.search(f'''\n",
    "\n",
    "word utf8={w}\n",
    "\n",
    "'''))\n",
    "\n",
    "len(find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
