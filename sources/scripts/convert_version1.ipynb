{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Version 1.0 NENA from 0.01\n",
    "\n",
    "We currently have all NENA texts stored in an older version of the\n",
    "NENA text-format, with some deprecated markdown strings (for example).\n",
    "In this notebook, we'll build the code to convert these version 0.01 texts\n",
    "into the new version 0.02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import unicodedata\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialects = Path('/Users/cody/github/CambridgeSemiticsLab/nena_corpus/texts/0.01')\n",
    "\n",
    "dialects2texts = collections.defaultdict(lambda: collections.defaultdict())\n",
    "\n",
    "for dialect_file in dialects.glob('*'):\n",
    "    dialect = dialect_file.name\n",
    "    for text_file in dialect_file.glob('*.nena'):\n",
    "        title = text_file.stem\n",
    "        text = text_file.read_text()\n",
    "        dialects2texts[dialect][title] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Barwar', 'Urmi_C'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialects2texts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A Hundred Gold Coins\n",
      "\n",
      "source: bar text a1-A7.html\n",
      "text_id: A6\n",
      "informant: Yuwəl Yuḥanna\n",
      "place: Dure\n",
      "\n",
      "(1) xá-ga xèta,ˈ mállah Naṣràdin,ˈ xázəx mòdi wíða.ˈ gu-bɛ̀θa wéwa,ˈ har-zála-w\n",
      "θàya.ˈ zála-w θàya,ˈ mára ya-ʾàlaha,ˈ yawə̀tliˈ ʾə́mma dàwe.ˈ ʾən-hàwaˈ ʾə́č̣č̣i-u\n",
      "ʾə́č̣č̣a maqəlbə̀nna.ˈ ʾu-ʾən-hàwaˈ ʾə́mma-w-xà-ži,ˈ la-băyə̀nna.ˈ de-šùqla.ˈ ʾə̀mma\n",
      "gắrəg háwa drə́st.ˈ (2) b-álaha hóle zála-w θàya,ˈ ʾíθwale xá-šwawa huðàya,ˈ\n",
      "maṣóθe ʾə́lle dìye.ˈ mə́re xázəx ʾáwwa dū̀s-ile.ˈ qɛ́mən mjarbə̀nne.ˈ síq\n"
     ]
    }
   ],
   "source": [
    "test = dialects2texts['Barwar']['A Hundred Gold Coins']\n",
    "\n",
    "print(test[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Modifications\n",
    "\n",
    "As much as possible, we'll use regex to clean out old markdown standards.\n",
    "We also have to do some surgery on the metadata section of each text.\n",
    "\n",
    "In some cases, we need to apply corrections to the underlying text due to problems\n",
    "that were left behind previously. We also do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_re = re.compile(r'^# ([^\\n]*)\\n\\n(.*?)\\n\\n(.*)', re.DOTALL)\n",
    "attributes = re.compile(r'(.*): (.*)?')\n",
    "\n",
    "def norm(text):\n",
    "    return unicodedata.normalize('NFD', text)\n",
    "\n",
    "# order of replacement patterns matters\n",
    "# we make a number of different edits, including \n",
    "# edits of existing standards as well as correcting\n",
    "# bad characters / encodings\n",
    "replacements = [\n",
    "    \n",
    "    # replace speaker tags\n",
    "    (re.compile(r'\\[([A-Za-z]+):(.*?)\\]', re.DOTALL), '«\\g<1>: \\g<2>»'),\n",
    "    \n",
    "    # replace emphases and language tags\n",
    "    (re.compile(r'<([A-Za-z]+)>\\*(.*?)\\*([.,]?)<[A-Za-z]+>', re.DOTALL), r'<\\g<1>:\\g<2>>\\g<3>'),\n",
    "    \n",
    "    # add missing lang tags for these elements\n",
    "    (\n",
    "        re.compile(norm(r'(ʾArmanəs-⁺tɑ̄̀n|⁺Hayə̀st[ɑa]n|ʾArmanə̀s-⁺tɑn|Téhrɑn|Šɑ̄h Abbɑ̄̀s)')),\n",
    "        '<?:\\g<1>>',\n",
    "    ),\n",
    "    \n",
    "    # replace blank emphases with unknown language tags\n",
    "    (re.compile(r'\\*(.*?)\\*', re.DOTALL), r'<?:\\g<1>>'),\n",
    "    \n",
    "    # add English language tag\n",
    "    (re.compile(norm('<\\?:(sýrop)>')), '<E:\\g<1>>'),\n",
    "    \n",
    "    # remove one interruption note\n",
    "    (re.compile(r'\\([^\\d]*?\\)\\s?\\n?', re.DOTALL), ''),\n",
    "    \n",
    "    # remove stylistic linebreak markers\n",
    "    (re.compile(r'\\/'), ''),\n",
    "     \n",
    "    # remove any footnotes at bottom of text\n",
    "    (re.compile(r'\\[\\^\\d*\\]:.*', re.DOTALL), ''),\n",
    "    \n",
    "    # remove any footnotes in body of text\n",
    "    (re.compile(r'\\[\\^\\d*\\]'), ''),\n",
    "    \n",
    "    # replace or correct idiosyncratic characters\n",
    "    (re.compile(r'\\u0248|\\u0249'), 'ɟ'),\n",
    "    (re.compile(r'\\u02b8'), 'y'),\n",
    "    (re.compile(r'ı'), 'i'),\n",
    "    (re.compile(r'ɑ'), 'a'),\n",
    "    (re.compile(norm(r'ĉ')),  norm('č')), \n",
    "    (re.compile(norm(r'p̂')), norm('p̭')),\n",
    "    (re.compile(norm('bŕatan')), norm('brátan')),\n",
    "    (re.compile(r'\\n—ˈ'), '\\nˈ —'),\n",
    "    (re.compile(r'ʾ⁺'), '⁺ʾ'), # switch places between ayin and +\n",
    "    (re.compile(r'([^ -:])(⁺)'), '\\g<1> \\g<2>'), # fix missing spaces \n",
    "    (re.compile(r' \\.\\. '), ' ... '),\n",
    "    (re.compile(r'\\.\\.\\.\\.+'), '...'),\n",
    "    (re.compile(r'  +'), ' '),\n",
    "    (re.compile(r'!\\.'), '!'), \n",
    "    \n",
    "    # add trailing space to any ellipses\n",
    "    (re.compile(r'(\\.\\.\\.)[^ \\n]', re.DOTALL), '... '),\n",
    "    \n",
    "    # merge a few side-by-side lang tags\n",
    "    (re.compile(norm(r'(⁺ʾávun <P:Nādər-Šā́h)> <P:(ʾafšā̀r>)')), '\\g<1> \\g<2>'),\n",
    "    (re.compile(norm(r'(<P:dādgā̀h)>ˈ <P:(dādgā́h>)')), '\\g<1>ˈ \\g<2>'),\n",
    "    (re.compile(norm(r'(<P:măʿammà)>ˈ <P:(măʿammà>)')), '\\g<1>ˈ \\g<2>'),\n",
    "    \n",
    "]\n",
    "\n",
    "def apply_replacements(text):\n",
    "    \"\"\"Iterate through re patterns and call sub on text.\"\"\"\n",
    "    for patt, replace in replacements:\n",
    "        text = patt.sub(replace, text)\n",
    "    return text.strip()\n",
    "        \n",
    "def metadata_block(dialect, title, meta_string):\n",
    "    \"\"\"Build metadata block for version 1.0\"\"\"\n",
    "    attribs = attributes.findall(meta_string)\n",
    "    attribs.insert(0, ('encoding', 'UTF8'))\n",
    "    attribs.insert(0, ('title', title))\n",
    "    attribs.insert(0, ('dialect', dialect))\n",
    "    return '\\n'.join(f'{attr.strip()} = {val.strip()}'\n",
    "                         for attr, val in attribs)\n",
    "def adjust_title(title_str):\n",
    "    \"\"\"Adjust deficiencies in the titles\"\"\"\n",
    "    first_letter = title_str[:1].upper()\n",
    "    return first_letter + title_str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test patterns\n",
    "\n",
    "# patt, repl = (re.compile(r'([^ -:])(⁺)'), '\\g<1> \\g<2>')\n",
    "# test = 'P:ʾəhtiyā̀j>⁺ʾallux.'\n",
    "# patt.sub(repl, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the replacements..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_texts = []\n",
    "\n",
    "new_dir = Path('/Users/cody/github/CambridgeSemiticsLab/nena_corpus/texts/1.0/')\n",
    "for dialect, texts in dialects2texts.items():\n",
    "    dialect_dir = new_dir.joinpath(f'{dialect}')\n",
    "    dialect_dir.mkdir(exist_ok=True)\n",
    "    for title, text in texts.items():\n",
    "        title, metadata, text = text_re.search(text).groups()\n",
    "        text = norm(text)\n",
    "        title = adjust_title(title)\n",
    "        meta_block = metadata_block(dialect, title, metadata)\n",
    "        text_block = apply_replacements(text)\n",
    "        new_text = meta_block + '\\n\\n' + text_block\n",
    "        filename = dialect_dir.joinpath(f'{title}.nena')\n",
    "        filename.write_text(new_text)\n",
    "        transformed_texts.append(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
